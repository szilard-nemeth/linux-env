
Hi [~werd.up],
Thanks for reporting this issue and congratulations for the first reported YARN jira.

{quote}
In the process of attempting to verify and validate the SLS output, I've encountered a number of issues including runtime exceptions and bad output. 
{quote}

I read through your observations and spent some time to play around with SLS.
As the process was repetitive, I created some scripts into my public Github repo here: https://github.com/szilard-nemeth/linux-env/tree/ff84652b34bc23c1f88766f781f6648365becde5/workplace-specific/cloudera/investigations/YARN-10427

Let me break these directories and scripts down: 
1. [config dir|https://github.com/szilard-nemeth/linux-env/tree/ff84652b34bc23c1f88766f781f6648365becde5/workplace-specific/cloudera/investigations/YARN-10427/config]: This is the exact same configuration file set that you attached to this jira, with one exception of the log4j.properties file, that turns on DEBUG logging for SLS.

2. [upstream-patches dir|https://github.com/szilard-nemeth/linux-env/tree/ff84652b34bc23c1f88766f781f6648365becde5/workplace-specific/cloudera/investigations/YARN-10427/upstream-patches]: This is the directory of the logging patch that helped see the issues more clearly.
My code changes are also pushed to my Hadoop fork: https://github.com/szilard-nemeth/hadoop/tree/YARN-10427-investigation

3. [scripts dir|https://github.com/szilard-nemeth/linux-env/tree/ff84652b34bc23c1f88766f781f6648365becde5/workplace-specific/cloudera/investigations/YARN-10427/scripts]: This is the directory that contains all my scripts to build Hadoop + launch SLS and save produced logs to the local machine.
As I have been working on a remote cluster, there's a script called [setup-vars-upstream.sh|https://github.com/szilard-nemeth/linux-env/blob/ff84652b34bc23c1f88766f781f6648365becde5/workplace-specific/cloudera/investigations/YARN-10427/scripts/setup-vars-upstream.sh] that contains some configuration values for the remote cluster + some local directories. If you want to use the scripts, all you need to do is to replace the configs in this file according to your environment.

3.1 [build-and-launch.sh|https://github.com/szilard-nemeth/linux-env/blob/ff84652b34bc23c1f88766f781f6648365becde5/workplace-specific/cloudera/investigations/YARN-10427/scripts/build-and-launch-sls.sh]: This is the script that builds Hadoop according to the environment variables and launches the SLS suites on the remote cluster.

3.2 [start-sls.sh|https://github.com/szilard-nemeth/linux-env/blob/ff84652b34bc23c1f88766f781f6648365becde5/workplace-specific/cloudera/investigations/YARN-10427/scripts/start-sls.sh]: This is the most important script as this will be executed on the remote machine. 
I think the script itself is straightforward enough, but let me briefly list what it does: 
- This script assumes that the Hadoop dist package is copied to the remote machine (this was done by [build-and-launch.sh|https://github.com/szilard-nemeth/linux-env/blob/ff84652b34bc23c1f88766f781f6648365becde5/workplace-specific/cloudera/investigations/YARN-10427/scripts/build-and-launch-sls.sh])
- Cleans up all Hadoop-related directories and extracts the Hadoop dist tar.gz
- Copies the config to Hadoop's config dirs so SLS will use these particular configs
- Launches SLS by starting slsrun.sh with the appropriate CLI swithces
- Greps for some useful data in the resulted SLS log file.

3.3 [launch-sls.sh|https://github.com/szilard-nemeth/linux-env/blob/ff84652b34bc23c1f88766f781f6648365becde5/workplace-specific/cloudera/investigations/YARN-10427/scripts/launch-sls.sh]: This script is executed by [build-and-launch.sh|https://github.com/szilard-nemeth/linux-env/blob/ff84652b34bc23c1f88766f781f6648365becde5/workplace-specific/cloudera/investigations/YARN-10427/scripts/build-and-launch-sls.sh] as its last step. Once the start-sls.sh is finished, the [save-latest-sls-logs.sh|https://github.com/szilard-nemeth/linux-env/blob/ff84652b34bc23c1f88766f781f6648365becde5/workplace-specific/cloudera/investigations/YARN-10427/scripts/save-latest-sls-logs.sh] script is started. As the name implies it saves the latest SLS log dir and SCPs it to the local machine. The target directory of the local machine is determined by the config ([setup-vars-upstream.sh|https://github.com/szilard-nemeth/linux-env/blob/ff84652b34bc23c1f88766f781f6648365becde5/workplace-specific/cloudera/investigations/YARN-10427/scripts/setup-vars-upstream.sh]).

TODO bold 
The latest logs and grepped logs for the SLS run is saved to my repo [here|https://github.com/szilard-nemeth/linux-env/tree/96ed3d8af9f4677866652bb57153713b29f24a98/workplace-specific/cloudera/investigations/YARN-10427/latest-logs/slsrun-out-20201222_040513]

h2. What causes the duplicate Job IDs (application ID)

1. The jobruntime.csv file is being written with class SchedulerMetrics, you can see the init part [here|https://github.com/apache/hadoop/blob/a89ca56a1b0eb949f56e7c6c5c25fdf87914a02f/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/scheduler/SchedulerMetrics.java#L180-L186].
 
2. The jobruntime records (lines of CSV file) are written with method [SchedulerMetrics#addAMRuntime|https://github.com/apache/hadoop/blob/a89ca56a1b0eb949f56e7c6c5c25fdf87914a02f/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/scheduler/SchedulerMetrics.java#L661-L674]. We only need to check the call hierarchy of this method to reveal the reason of duplicate application IDs.

2.1 Call hierarchy #1 (From bottom to top):
	org.apache.hadoop.yarn.sls.scheduler.SchedulerMetrics#addAMRuntime
		org.apache.hadoop.yarn.sls.appmaster.AMSimulator#lastStep
			org.apache.hadoop.yarn.sls.appmaster.MRAMSimulator#lastStep
				org.apache.hadoop.yarn.sls.appmaster.MRAMSimulator#processResponseQueue

2.2 Call hierarchy #2 (From bottom to top):
	org.apache.hadoop.yarn.sls.scheduler.SchedulerMetrics#addAMRuntime
		org.apache.hadoop.yarn.sls.appmaster.AMSimulator#lastStep
			org.apache.hadoop.yarn.sls.scheduler.TaskRunner.Task#run

3. These duplicate calls of MRAMSimulator#lastStep can be easily justified with the logs as well. [apps-shuttingdown.log|https://github.com/szilard-nemeth/linux-env/blob/0d41e4dbda5e3a22105c4fe27f540ae8004857fe/workplace-specific/cloudera/investigations/YARN-10427/latest-logs/slsrun-out-20201222_040513/grepped/apps-shuttingdown.log]
In this logfile, it's clearly visible that 9 apps (application_1608638719822_0001 - application_1608638719822_0009) are "shutting down" 2 times. 
This is because the MRAMSimulator#lastStep is called twice.
As MRAMSimulator#lastStep calls org.apache.hadoop.yarn.sls.appmaster.AMSimulator#lastStep (super method), I added some logging that prints the stacktrace of lastStep method calls: [AMSimulator#lastStep|https://github.com/szilard-nemeth/hadoop/blob/10d9d9ff3446583b3b2b6e4518ad0c3ea335da48/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/appmaster/AMSimulator.java#L223-L225].

Let's take application_1608638719822_0001 as an example with this file: [laststep-calls-for-app0001.log|https://github.com/szilard-nemeth/linux-env/blob/96ed3d8af9f4677866652bb57153713b29f24a98/workplace-specific/cloudera/investigations/YARN-10427/latest-logs/slsrun-out-20201222_040513/laststep-calls-for-app0001.log]

4. Checking the 2 stacktraces:

4.1 Stacktrace #1: Call to lastStep from MRAMSimulator#processResponseQueue, when all mappers/reducers are finished:
{code}
at org.apache.hadoop.yarn.sls.appmaster.AMSimulator.lastStep(AMSimulator.java:224)
	at org.apache.hadoop.yarn.sls.appmaster.MRAMSimulator.lastStep(MRAMSimulator.java:401)
	at org.apache.hadoop.yarn.sls.appmaster.MRAMSimulator.processResponseQueue(MRAMSimulator.java:195)
	at org.apache.hadoop.yarn.sls.appmaster.AMSimulator.middleStep(AMSimulator.java:212)
	at org.apache.hadoop.yarn.sls.scheduler.TaskRunner$Task.run(TaskRunner.java:101)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
{code}

[TaskRunner$Task.run|https://github.com/szilard-nemeth/hadoop/blob/10d9d9ff3446583b3b2b6e4518ad0c3ea335da48/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/scheduler/TaskRunner.java#L101] calls AMSimulator#middleStep.
Then, in [MRAMSimulator.processResponseQueue|https://github.com/szilard-nemeth/hadoop/blob/10d9d9ff3446583b3b2b6e4518ad0c3ea335da48/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/appmaster/MRAMSimulator.java#L194-L196], there's a code piece that checks for completed mappers and reducers. 
If the finished mappers are greater than or equal to all mappers and same with reducers, the lastStep will be called.
{code}
if (mapFinished >= mapTotal && reduceFinished >= reduceTotal) {
  lastStep();
}
{code}

Stacktrace #2: Call to lastStep from [TaskRunner$Task.run|https://github.com/szilard-nemeth/hadoop/blob/10d9d9ff3446583b3b2b6e4518ad0c3ea335da48/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/scheduler/TaskRunner.java#L89-L113]
{code}
	at org.apache.hadoop.yarn.sls.appmaster.AMSimulator.lastStep(AMSimulator.java:224)
	at org.apache.hadoop.yarn.sls.appmaster.MRAMSimulator.lastStep(MRAMSimulator.java:401)
	at org.apache.hadoop.yarn.sls.scheduler.TaskRunner$Task.run(TaskRunner.java:106)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
{code}

According my code inspections, all NMs and AMs are scheduled with this TaskRunner from SLSRunner.
The call hierarchy of a launch of an AM is this (from bottom to top):

TaskRunner.schedule(Task)  (org.apache.hadoop.yarn.sls.scheduler)
	SLSRunner.runNewAM(String, String, String, String, long, long, List<ContainerSimulator>, ...)  (org.apache.hadoop.yarn.sls)
		SLSRunner.runNewAM(String, String, String, String, long, long, List<ContainerSimulator>, ...)  (org.apache.hadoop.yarn.sls)
			SLSRunner.createAMForJob(Map)  (org.apache.hadoop.yarn.sls)
				SLSRunner.startAMFromSLSTrace(String)  (org.apache.hadoop.yarn.sls)
					SLSRunner.startAM()  (org.apache.hadoop.yarn.sls)
						SLSRunner.start()  (org.apache.hadoop.yarn.sls)
							SLSRunner.run(String[])  (org.apache.hadoop.yarn.sls)

As an implementation of the AM is class of [AMSimulator|https://github.com/szilard-nemeth/hadoop/blob/10d9d9ff3446583b3b2b6e4518ad0c3ea335da48/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/appmaster/AMSimulator.java] that extends TaskRunner.Task, that implements the Runnable interface, all interesting things are happening in [org.apache.hadoop.yarn.sls.scheduler.TaskRunner.Task#run|https://github.com/szilard-nemeth/hadoop/blob/10d9d9ff3446583b3b2b6e4518ad0c3ea335da48/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/scheduler/TaskRunner.java#L89-L113].
Initially, the field nextTime is equal to startTime, so the firstStep method is invoked.
For subsequent calls of run and while nextRun < endTime, middleStep is executed.
The field called 'nextRun' is always incremented with repeatInterval (which is 1000ms with the provided config). 
This means that all AMSimulator tasks are getting scheduled in every second.
Once 'nextRun' reaches 'endTime' (it becomes greater) then lastStep will be called.

.h2 Conclusion for duplicate Job IDs
These 2 calls to lastStep are the main reason of the duplicate applicationID in the jobruntime.csv file.
It's not trivial for me why this lastStep method is invoked through [AMSimulator#middleStep|https://github.com/szilard-nemeth/hadoop/blob/10d9d9ff3446583b3b2b6e4518ad0c3ea335da48/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/appmaster/AMSimulator.java#L209] and ultimately through [AMSimulator#processResponseQueue|https://github.com/szilard-nemeth/hadoop/blob/10d9d9ff3446583b3b2b6e4518ad0c3ea335da48/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/appmaster/AMSimulator.java#L212] and from the main loop of the TaskRunner$Task.
This method should be invoked only once per AM!

What is even more interesting that 9 out of 10 apps had this method called twice according to this log file: [apps-shuttingdown.log|https://github.com/szilard-nemeth/linux-env/blob/0d41e4dbda5e3a22105c4fe27f540ae8004857fe/workplace-specific/cloudera/investigations/YARN-10427/latest-logs/slsrun-out-20201222_040513/grepped/apps-shuttingdown.log]
.
But for the last application it is only called once: 
{code}
2020-12-22 04:09:47,892 INFO appmaster.AMSimulator: Application application_1608638719822_0010 is shutting down. lastStep Stacktrace
{code}
All I can see is that the only call to lastStep for app 0010 is this:
(This is from [log file|https://raw.githubusercontent.com/szilard-nemeth/linux-env/master/workplace-specific/cloudera/investigations/YARN-10427/latest-logs/slsrun-out-20201222_040513/output.log])
{code}
2020-12-22 04:09:47,892 INFO appmaster.AMSimulator: Application application_1608638719822_0010 is shutting down. lastStep Stacktrace
java.lang.Exception
	at org.apache.hadoop.yarn.sls.appmaster.AMSimulator.lastStep(AMSimulator.java:224)
	at org.apache.hadoop.yarn.sls.appmaster.MRAMSimulator.lastStep(MRAMSimulator.java:401)
	at org.apache.hadoop.yarn.sls.appmaster.MRAMSimulator.processResponseQueue(MRAMSimulator.java:195)
	at org.apache.hadoop.yarn.sls.appmaster.AMSimulator.middleStep(AMSimulator.java:212)
	at org.apache.hadoop.yarn.sls.scheduler.TaskRunner$Task.run(TaskRunner.java:101)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
{code}

This is the call from MRAMSimulator.processResponseQueue that verifies the number of completed mappers/reducers.
The other call that checks the timestamps in TaskRunner$Task.run is not called, meaning that the last application never reaches its intended running time.
This could be counted as "another bug", but unfortunately I wasn't be able to find out why this anomaly happens.

.h2 Other observations
If I grep for any container ID that belongs to any of the 9 applications that had duplicate Job IDs in the jobruntime.csv file, each of the apps have a log record like this in the output.log: 
{code}
2020-12-22 04:07:11,980 INFO scheduler.AbstractYarnScheduler: Container container_1608638719822_0001_01_000001 completed with event FINISHED, but corresponding RMContainer doesn't exist.
{code}
[See an example here|https://github.com/szilard-nemeth/linux-env/blob/96ed3d8af9f4677866652bb57153713b29f24a98/workplace-specific/cloudera/investigations/YARN-10427/latest-logs/slsrun-out-20201222_040513/grepped/container_1608638719822_0001_01_000001.log#L32]
I think this is also happening because of the duplicate call to the lastStep method.


.h2 Possible fix for duplicate Job IDs
The task is to prevent lastStep to be called twice.
Without understanding the reason of the two calls above and the potential side-effects of the removal of any of these calls, let's check what lastStep does.
The implementation of lastStep for MRAMSimulator delegates to the superclass: [AMSimulator#lastStep|https://github.com/szilard-nemeth/hadoop/blob/10d9d9ff3446583b3b2b6e4518ad0c3ea335da48/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/appmaster/AMSimulator.java#L222-L273].
There are several things happening in this method: 
- App is unregistered / untracked.
- If the amContainer is not null, the NM of the AM will be notified and the AM container will be marked as completed [here|https://github.com/szilard-nemeth/hadoop/blob/10d9d9ff3446583b3b2b6e4518ad0c3ea335da48/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/appmaster/AMSimulator.java#L231-L238]
- The AM is unregistered from the RM [here|https://github.com/szilard-nemeth/hadoop/blob/10d9d9ff3446583b3b2b6e4518ad0c3ea335da48/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/appmaster/AMSimulator.java#L246-L263].
- The finish time of the AM is set, this is the only write access of this field: [here|https://github.com/szilard-nemeth/hadoop/blob/10d9d9ff3446583b3b2b6e4518ad0c3ea335da48/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/appmaster/AMSimulator.java#L265].
- The job's runtime information will be persisted to the jobruntime.csv file [here|https://github.com/szilard-nemeth/hadoop/blob/10d9d9ff3446583b3b2b6e4518ad0c3ea335da48/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/appmaster/AMSimulator.java#L266-L272].

I think all of these actions must be prevented to be called more than once!

As there are not too many field updates in the lastStep method, without introducing a new boolean flag to track if lastStep was called or not, a quick and dirty solution is to check if the org.apache.hadoop.yarn.sls.appmaster.AMSimulator#simulateFinishTimeMS field is modified (i.e. greater then zero, which is the default value of long). As the only writer of this field is one write occurrence from the lastStep method, it's safe to check this. If it is not null, it means lastStep was called before.

.h2 Test run with the fix
The fix patch is added [here|https://github.com/szilard-nemeth/linux-env/blob/9bd94311a900b79764d2ee26db16aed312a7fff7/workplace-specific/cloudera/investigations/YARN-10427/upstream-patches/0002-YARN-10427-Prevent-second-call-of-AMSimulator-lastSt.patch]
It is also uploaded as an attachment to this jira, as a candidate for commit as I think it's a proper fix.
TODO upload patch to jira
The logs of the "fixed run" can be found here: https://github.com/szilard-nemeth/linux-env/tree/9bd94311a900b79764d2ee26db16aed312a7fff7/workplace-specific/cloudera/investigations/YARN-10427/fixed-logs


1. The shutting down messages for applications look way better, there's only 10 messages and 10 apps, which is correct: [apps-shuttingdown.log|https://github.com/szilard-nemeth/linux-env/blob/master/workplace-specific/cloudera/investigations/YARN-10427/fixed-logs/grepped/apps-shuttingdown.log]

2. The [jobruntime.csv|https://github.com/szilard-nemeth/linux-env/blob/9bd94311a900b79764d2ee26db16aed312a7fff7/workplace-specific/cloudera/investigations/YARN-10427/fixed-logs/jobruntime.csv] file also looks good. There's one entry per application now.

3. In the [output.log|https://github.com/szilard-nemeth/linux-env/blob/9bd94311a900b79764d2ee26db16aed312a7fff7/workplace-specific/cloudera/investigations/YARN-10427/fixed-logs/output.log] file, there are still weird messages when the AM container is finished, for all the apps: 
{code}
root@snemeth-fips2-1 slsrun-out-20201222_063242]# grep "but corresponding RMContainer doesn't exist" output.log 
2020-12-22 06:34:40,315 INFO scheduler.AbstractYarnScheduler: Container container_1608647568797_0002_01_000001 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2020-12-22 06:34:41,315 INFO scheduler.AbstractYarnScheduler: Container container_1608647568797_0001_01_000001 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2020-12-22 06:35:05,315 INFO scheduler.AbstractYarnScheduler: Container container_1608647568797_0003_01_000001 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2020-12-22 06:35:10,315 INFO scheduler.AbstractYarnScheduler: Container container_1608647568797_0005_01_000001 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2020-12-22 06:35:30,315 INFO scheduler.AbstractYarnScheduler: Container container_1608647568797_0006_01_000001 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2020-12-22 06:36:04,315 INFO scheduler.AbstractYarnScheduler: Container container_1608647568797_0009_01_000001 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2020-12-22 06:36:04,373 INFO scheduler.AbstractYarnScheduler: Container container_1608647568797_0008_01_000001 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2020-12-22 06:36:20,315 INFO scheduler.AbstractYarnScheduler: Container container_1608647568797_0004_01_000001 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2020-12-22 06:36:26,315 INFO scheduler.AbstractYarnScheduler: Container container_1608647568797_0007_01_000001 completed with event FINISHED, but corresponding RMContainer doesn't exist.
{code}
So in contrary to my expectations, this is not because of the double-call of lastStep.


TODO tar gz all scripts + logs and attach to jira


