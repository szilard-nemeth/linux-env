diff --git a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/resources/log4j.properties b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/resources/log4j.properties
index 81a3f6ad5d2..3fff63bc263 100644
--- a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/resources/log4j.properties
+++ b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/resources/log4j.properties
@@ -17,3 +17,5 @@ log4j.threshold=ALL
 log4j.appender.stdout=org.apache.log4j.ConsoleAppender
 log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
 log4j.appender.stdout.layout.ConversionPattern=%d{ISO8601} %-5p [%t] %c{2} (%F:%M(%L)) - %m%n
+log4j.logger.io.netty=DEBUG
+log4j.logger.org.apache.hadoop.mapred=DEBUG
\ No newline at end of file
diff --git a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java
index a95da1deebd..b7e1c09ac7f 100644
--- a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java
+++ b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java
@@ -29,6 +29,7 @@
 import static io.netty.handler.codec.http.HttpResponseStatus.OK;
 import static io.netty.handler.codec.http.HttpResponseStatus.UNAUTHORIZED;
 import static io.netty.handler.codec.http.HttpVersion.HTTP_1_1;
+import static org.apache.hadoop.mapred.ShuffleHandler.NettyChannelHelper.*;
 import static org.fusesource.leveldbjni.JniDBFactory.asString;
 import static org.fusesource.leveldbjni.JniDBFactory.bytes;
 
@@ -186,6 +187,7 @@
   // This should kept in sync with Fetcher.FETCH_RETRY_DELAY_DEFAULT
   public static final long FETCH_RETRY_DELAY = 1000L;
   public static final String RETRY_AFTER_HEADER = "Retry-After";
+  static final String ENCODER_HANDLER_NAME = "encoder";
 
   private int port;
   private EventLoopGroup bossGroup;
@@ -199,8 +201,9 @@
   protected HttpPipelineFactory pipelineFact;
   private int sslFileBufferSize;
 
-  //TODO snemeth add a config option for this later, this is temporarily disabled for now.
+  //TODO snemeth add a config option for these later, this is temporarily disabled for now.
   private boolean useOutboundExceptionHandler = false;
+  private boolean useOutboundLogger = false;
   
   /**
    * Should the shuffle use posix_fadvise calls to manage the OS cache during
@@ -299,6 +302,36 @@ public void operationComplete(ChannelFuture future) throws Exception {
       shuffleConnections.decr();
     }
   }
+  
+  static class NettyChannelHelper {
+    static ChannelFuture writeToChannel(Channel ch, Object obj) {
+      LOG.debug("Writing {} to channel: {}", obj.getClass().getSimpleName(), ch.id());
+      return ch.writeAndFlush(obj);
+    }
+
+    static void writeToChannelAndClose(Channel ch, Object obj) {
+      writeToChannel(ch, obj).addListener(ChannelFutureListener.CLOSE);
+    }
+
+    static ChannelFuture writeToChannelAndAddLastHttpContent(Channel ch, HttpResponse obj) {
+      writeToChannel(ch, obj);
+      return writeLastHttpContentToChannel(ch);
+    }
+
+    static ChannelFuture writeLastHttpContentToChannel(Channel ch) {
+      LOG.debug("Writing LastHttpContent, channel id: {}", ch.id());
+      return ch.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT);
+    }
+
+    static void closeChannel(Channel ch) {
+      LOG.debug("Closing channel, channel id: {}", ch.id());
+      ch.close();
+    }
+
+    static void closeChannels(ChannelGroup channelGroup) {
+      channelGroup.close().awaitUninterruptibly(10, TimeUnit.SECONDS);
+    }
+  }
 
   private final MetricsSystem ms;
   final ShuffleMetrics metrics;
@@ -316,12 +349,15 @@ public void operationComplete(ChannelFuture future) throws Exception {
       LOG.trace("operationComplete");
       if (!future.isSuccess()) {
         LOG.error("Future is unsuccessful. Cause: ", future.cause());
-        LOG.debug("Closing channel");
-        future.channel().close();
+        closeChannel(future.channel());
         return;
       }
       int waitCount = this.reduceContext.getMapsToWait().decrementAndGet();
       if (waitCount == 0) {
+        LOG.trace("Finished with all map outputs");
+        //HADOOP-15327: Need to send an instance of LastHttpContent to define HTTP
+        //message boundaries. See details in jira.
+        writeLastHttpContentToChannel(future.channel());
         metrics.operationComplete(future);
         // Let the idle timer handler close keep-alive connections
         if (reduceContext.getKeepAlive()) {
@@ -330,10 +366,10 @@ public void operationComplete(ChannelFuture future) throws Exception {
               (TimeoutHandler)pipeline.get(TIMEOUT_HANDLER);
           timeoutHandler.setEnabledTimeout(true);
         } else {
-          LOG.debug("Closing channel");
-          future.channel().close();
+          closeChannel(future.channel());
         }
       } else {
+        LOG.trace("operationComplete, waitCount > 0, invoking sendMap with reduceContext");
         pipelineFact.getSHUFFLE().sendMap(reduceContext);
       }
     }
@@ -594,7 +630,7 @@ protected void serviceStart() throws Exception {
 
   @Override
   protected void serviceStop() throws Exception {
-    accepted.close().awaitUninterruptibly(10, TimeUnit.SECONDS);
+    closeChannels(accepted);
 
     if (pipelineFact != null) {
       pipelineFact.destroy();
@@ -827,7 +863,7 @@ void setEnabledTimeout(boolean enabledTimeout) {
     public void channelIdle(ChannelHandlerContext ctx, IdleStateEvent e) {
       if (e.state() == IdleState.WRITER_IDLE && enabledTimeout) {
         LOG.debug("Closing channel as writer was idle for {} seconds", connectionKeepAliveTimeOut);
-        ctx.channel().close();
+        closeChannel(ctx.channel());
       }
     }
   }
@@ -864,13 +900,20 @@ public void destroy() {
       }
       pipeline.addLast("decoder", new HttpRequestDecoder());
       pipeline.addLast("aggregator", new HttpObjectAggregator(1 << 16));
-      pipeline.addLast("encoder", new HttpResponseEncoder());
+      pipeline.addLast(ENCODER_HANDLER_NAME, new HttpResponseEncoder());
       pipeline.addLast("chunking", new ChunkedWriteHandler());
       pipeline.addLast("shuffle", SHUFFLE);
-      
+      addOutboundHandlersIfRequired(pipeline);
+      pipeline.addLast(TIMEOUT_HANDLER, new TimeoutHandler(connectionKeepAliveTimeOut));
+      // TODO factor security manager into pipeline
+      // TODO factor out encode/decode to permit binary shuffle
+      // TODO factor out decode of index to permit alt. models
+    }
+
+    private void addOutboundHandlersIfRequired(ChannelPipeline pipeline) {
       if (useOutboundExceptionHandler) {
         //https://stackoverflow.com/questions/50612403/catch-all-exception-handling-for-outbound-channelhandler
-        pipeline.addLast("outboundExcHandler", new ChannelOutboundHandlerAdapter() {
+        pipeline.addLast("outboundExceptionHandler", new ChannelOutboundHandlerAdapter() {
           @Override
           public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception {
             promise.addListener(ChannelFutureListener.FIRE_EXCEPTION_ON_FAILURE);
@@ -878,10 +921,11 @@ public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise)
           }
         });
       }
-      pipeline.addLast(TIMEOUT_HANDLER, new TimeoutHandler(connectionKeepAliveTimeOut));
-      // TODO factor security manager into pipeline
-      // TODO factor out encode/decode to permit binary shuffle
-      // TODO factor out decode of index to permit alt. models
+      if (useOutboundLogger) {
+        //Replace HttpResponseEncoder with LoggingHttpResponseEncoder
+        //Need to use the same name as before, otherwise we would have 2 encoders 
+        pipeline.replace(ENCODER_HANDLER_NAME, ENCODER_HANDLER_NAME, new LoggingHttpResponseEncoder(false));
+      }
     }
   }
 
@@ -968,6 +1012,7 @@ public void channelActive(ChannelHandlerContext ctx)
 
     @Override
     public void channelInactive(ChannelHandlerContext ctx) throws Exception {
+      LOG.trace("channelInactive");
       super.channelInactive(ctx);
       acceptedConnections.decrementAndGet();
       LOG.debug("New value of Accepted number of connections={}",
@@ -977,8 +1022,9 @@ public void channelInactive(ChannelHandlerContext ctx) throws Exception {
     @Override
     public void channelRead(ChannelHandlerContext ctx, Object msg)
         throws Exception {
-      LOG.debug("channelRead");
+      LOG.trace("channelRead");
       HttpRequest request = (HttpRequest) msg;
+      LOG.debug("Received HTTP request: {}", request);
       if (request.method() != GET) {
           sendError(ctx, METHOD_NOT_ALLOWED);
           return;
@@ -1077,38 +1123,29 @@ public void channelRead(ChannelHandlerContext ctx, Object msg)
         // is quite a non-standard way of crafting HTTP responses,
         // but we need to keep backward compatibility.
         // See more details in jira.
-        ch.writeAndFlush(response);
-        ch.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT);
-        LOG.error("Shuffle error in populating headers :", e);
+        writeToChannelAndAddLastHttpContent(ch, response);
+        LOG.error("Shuffle error while populating headers", e);
         String errorMessage = getErrorMessage(e);
-        sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);
+        sendError(ctx, errorMessage , INTERNAL_SERVER_ERROR);
         return;
       }
-      LOG.debug("Writing response: " + response);
-      ch.writeAndFlush(response).addListener(new ChannelFutureListener() {
-        @Override
-        public void operationComplete(ChannelFuture future) {
-          if (future.isSuccess()) {
-            LOG.debug("Written HTTP response object successfully");
-          } else {
-            LOG.error("Error while writing HTTP response object: {}", response);
-          }
+      writeToChannel(ch, response).addListener((ChannelFutureListener) future -> {
+        if (future.isSuccess()) {
+          LOG.debug("Written HTTP response object successfully");
+        } else {
+          LOG.error("Error while writing HTTP response object: {}. Cause: {}", response, future.cause());
         }
       });
       //Initialize one ReduceContext object per channelRead call
       boolean keepAlive = keepAliveParam || connectionKeepAliveEnabled;
       ReduceContext reduceContext = new ReduceContext(mapIds, reduceId, ctx,
           user, mapOutputInfoMap, jobId, keepAlive);
-      LOG.debug("After response");
       for (int i = 0; i < Math.min(maxSessionOpenFiles, mapIds.size()); i++) {
         ChannelFuture nextMap = sendMap(reduceContext);
         if(nextMap == null) {
           return;
         }
       }
-      //HADOOP-15327: Need to send an instance of LastHttpContent to define HTTP
-      //message boundaries. See details in jira.
-      ch.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT);
     }
 
     /**
@@ -1123,7 +1160,7 @@ public void operationComplete(ChannelFuture future) {
      */
     public ChannelFuture sendMap(ReduceContext reduceContext)
         throws Exception {
-
+      LOG.trace("Executing sendMap");
       ChannelFuture nextMap = null;
       if (reduceContext.getMapsToSend().get() <
           reduceContext.getMapIds().size()) {
@@ -1136,12 +1173,14 @@ public ChannelFuture sendMap(ReduceContext reduceContext)
             info = getMapOutputInfo(mapId, reduceContext.getReduceId(),
                 reduceContext.getJobId(), reduceContext.getUser());
           }
+          LOG.trace("Calling sendMapOutput.");
           nextMap = sendMapOutput(
               reduceContext.getCtx(),
               reduceContext.getCtx().channel(),
               reduceContext.getUser(), mapId,
               reduceContext.getReduceId(), info);
           if (null == nextMap) {
+            //This can only happen if spill file was not found
             sendError(reduceContext.getCtx(), NOT_FOUND);
             return null;
           }
@@ -1158,6 +1197,9 @@ public ChannelFuture sendMap(ReduceContext reduceContext)
           return null;
         }
       }
+      if (nextMap == null) {
+        LOG.trace("Returning nextMap: null");
+      }
       return nextMap;
     }
 
@@ -1232,7 +1274,6 @@ protected void populateHeaders(List<String> mapIds, String jobId,
             outputInfo.indexRecord.rawLength, reduce);
         DataOutputBuffer dob = new DataOutputBuffer();
         header.write(dob);
-
         contentLength += outputInfo.indexRecord.partLength;
         contentLength += dob.getLength();
       }
@@ -1336,7 +1377,7 @@ protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,
         new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);
       final DataOutputBuffer dob = new DataOutputBuffer();
       header.write(dob);
-      ch.writeAndFlush(wrappedBuffer(dob.getData(), 0, dob.getLength()));
+      writeToChannel(ch, wrappedBuffer(dob.getData(), 0, dob.getLength()));
       final File spillfile =
           new File(mapOutputInfo.mapOutputFileName.toString());
       RandomAccessFile spill;
@@ -1352,7 +1393,7 @@ protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,
             info.startOffset, info.partLength, manageOsCache, readaheadLength,
             readaheadPool, spillfile.getAbsolutePath(), 
             shuffleBufferSize, shuffleTransferToAllowed);
-        writeFuture = ch.writeAndFlush(partition);
+        writeFuture = writeToChannel(ch, partition);
         writeFuture.addListener(new ChannelFutureListener() {
             // TODO error handling; distinguish IO/connection failures,
             //      attribute to appropriate spill output
@@ -1370,7 +1411,7 @@ public void operationComplete(ChannelFuture future) {
             info.startOffset, info.partLength, sslFileBufferSize,
             manageOsCache, readaheadLength, readaheadPool,
             spillfile.getAbsolutePath());
-        writeFuture = ch.writeAndFlush(chunk);
+        writeFuture = writeToChannel(ch, chunk);
       }
       metrics.shuffleConnections.incr();
       metrics.shuffleOutputBytes.incr(info.partLength); // optimistic
@@ -1402,12 +1443,13 @@ protected void sendError(ChannelHandlerContext ctx, String msg,
       }
 
       // Close the connection as soon as the error message is sent.
-      ctx.channel().writeAndFlush(response).addListener(ChannelFutureListener.CLOSE);
+      writeToChannelAndClose(ctx.channel(), response);
     }
 
     @Override
     public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause)
         throws Exception {
+      LOG.debug("Executing exceptionCaught");
       Channel ch = ctx.channel();
       if (cause instanceof TooLongFrameException) {
         sendError(ctx, BAD_REQUEST);
@@ -1430,7 +1472,7 @@ public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause)
       }
     }
   }
-  
+
   static class AttemptPathInfo {
     // TODO Change this over to just store local dir indices, instead of the
     // entire path. Far more efficient.
diff --git a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/java/org/apache/hadoop/mapred/TestShuffleHandler.java b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/java/org/apache/hadoop/mapred/TestShuffleHandler.java
index 3e42f9b8cb8..033a850c1a1 100644
--- a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/java/org/apache/hadoop/mapred/TestShuffleHandler.java
+++ b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/java/org/apache/hadoop/mapred/TestShuffleHandler.java
@@ -17,8 +17,8 @@
  */
 package org.apache.hadoop.mapred;
 
+import io.netty.channel.ChannelFutureListener;
 import io.netty.channel.DefaultFileRegion;
-import org.apache.commons.compress.changes.ChangeSetPerformer;
 import org.apache.hadoop.thirdparty.com.google.common.collect.Maps;
 import io.netty.channel.AbstractChannel;
 import io.netty.channel.Channel;
@@ -41,6 +41,7 @@
 import static org.apache.hadoop.test.MetricsAsserts.getMetrics;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.fail;
 import static org.junit.Assume.assumeTrue;
 import static org.mockito.ArgumentMatchers.anyString;
 import static org.mockito.Mockito.mock;
@@ -53,15 +54,18 @@
 import java.io.FileInputStream;
 import java.io.FileOutputStream;
 import java.io.IOException;
+import java.io.InputStream;
 import java.net.HttpURLConnection;
 import java.net.InetSocketAddress;
 import java.net.Proxy;
 import java.net.Socket;
 import java.net.URL;
 import java.net.SocketAddress;
+import java.net.URLConnection;
 import java.nio.ByteBuffer;
 import java.nio.channels.ClosedChannelException;
 import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
@@ -105,6 +109,7 @@
 import org.apache.hadoop.yarn.server.api.AuxiliaryLocalPathHandler;
 import org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer;
 import org.apache.hadoop.yarn.server.records.Version;
+import org.hamcrest.CoreMatchers;
 import org.junit.After;
 import org.junit.Assert;
 import org.junit.Before;
@@ -125,11 +130,12 @@
   private static final File ABS_LOG_DIR = GenericTestUtils.getTestDir(
       TestShuffleHandler.class.getSimpleName() + "LocDir");
   private static final long ATTEMPT_ID = 12345L;
+  private static final long ATTEMPT_ID_2 = 12346L;
   
 
   //Control test execution properties with these flags
   private static final boolean DEBUG_MODE = false;
-  //If this is set to true and proxy server is not running, tests will fail!
+  //WARNING: If this is set to true and proxy server is not running, tests will fail!
   private static final boolean USE_PROXY = false; 
   private static final int HEADER_WRITE_COUNT = 100000;
   private static TestExecution TEST_EXECUTION;
@@ -175,15 +181,55 @@ int shuffleHandlerPort() {
         return DEFAULT_PORT;
       }
     }
+    
+    void parameterizeConnection(URLConnection conn) {
+      if (DEBUG_MODE) {
+        conn.setReadTimeout(1000000);
+        conn.setConnectTimeout(1000000);
+      }
+    }
+  }
+  
+  private static class ResponseConfig {
+    private static final int ONE_HEADER_DISPLACEMENT = 1;
+    
+    private final int headerWriteCount;
+    private final int mapOutputCount;
+    private final int contentLengthOfMapOutputs;
+    private long actualHeaderWriteCount;
+    private long headerContentLength;
+    private long headerSize;
+    public long responseContentLength;
+
+    public ResponseConfig(int headerWriteCount, int mapOutputCount, int contentLengthOfMapOutputs) {
+      if (mapOutputCount <= 0) {
+        throw new IllegalStateException("mapOutputCount should be at least 1");
+      }
+      this.headerWriteCount = headerWriteCount;
+      this.mapOutputCount = mapOutputCount;
+      this.contentLengthOfMapOutputs = contentLengthOfMapOutputs;
+      //MapOutputSender#send will send header N + 1 times
+      //So, (N + 1) * headerSize should be the content-length header + the expected content length as well
+      this.actualHeaderWriteCount = headerWriteCount + ONE_HEADER_DISPLACEMENT;
+    }
+
+    private void setHeaderSize(long headerSize) {
+      this.headerSize = headerSize;
+      this.headerContentLength = actualHeaderWriteCount * headerSize;
+      this.responseContentLength = (headerContentLength + contentLengthOfMapOutputs) * mapOutputCount;
+      LOG.debug("Content length of header: {}", headerContentLength);
+      LOG.debug("Content length of file chunks: {}", contentLengthOfMapOutputs);
+      LOG.debug("HTTP response content length: {}", responseContentLength);
+    }
   }
   
   private enum ShuffleUrlType {
-    SIMPLE, WITH_KEEPALIVE
+    SIMPLE, WITH_KEEPALIVE, WITH_KEEPALIVE_MULTIPLE_MAP_IDS, WITH_KEEPALIVE_NO_MAP_IDS
   }
 
   private static class InputStreamReadResult {
     final String asString;
-    final int totalBytesRead;
+    int totalBytesRead;
 
     public InputStreamReadResult(byte[] bytes, int totalBytesRead) {
       this.asString = new String(bytes, StandardCharsets.UTF_8);
@@ -191,40 +237,43 @@ public InputStreamReadResult(byte[] bytes, int totalBytesRead) {
     }
   }
 
+  private static abstract class AdditionalMapOutputSenderOperations {
+    public abstract ChannelFuture perform(ChannelHandlerContext ctx, Channel ch) throws IOException;
+  }
+
   private class ShuffleHandlerForKeepAliveTests extends ShuffleHandler {
-    final int headerWriteCount;
     final LastSocketAddress lastSocketAddress = new LastSocketAddress();
     final ArrayList<Throwable> failures = new ArrayList<>();
     final ShuffleHeaderProvider shuffleHeaderProvider;
     final HeaderPopulator headerPopulator;
-    final MapOutputSender mapOutputSender;
-    private final int expectedResponseSize;
+    MapOutputSender mapOutputSender;
     private Consumer<IdleStateEvent> channelIdleCallback;
     private CustomTimeoutHandler customTimeoutHandler;
+    private boolean failImmediatelyOnErrors = false;
+    private boolean closeChannelOnError = true;
+    private ResponseConfig responseConfig;
 
-    public ShuffleHandlerForKeepAliveTests(int headerWriteCount, long attemptId,
+    public ShuffleHandlerForKeepAliveTests(long attemptId, ResponseConfig responseConfig,
         Consumer<IdleStateEvent> channelIdleCallback) throws IOException {
-      this(headerWriteCount, attemptId);
+      this(attemptId, responseConfig);
       this.channelIdleCallback = channelIdleCallback;
     }
 
-    public ShuffleHandlerForKeepAliveTests(int headerWriteCount, long attemptId) throws IOException {
-      this.headerWriteCount = headerWriteCount;
-      shuffleHeaderProvider = new ShuffleHeaderProvider(attemptId);
-      headerPopulator = new HeaderPopulator(this, headerWriteCount, true,
-          shuffleHeaderProvider);
-      mapOutputSender = new MapOutputSender(this, headerWriteCount, lastSocketAddress, shuffleHeaderProvider);
-      int headerSize = getShuffleHeaderSize(shuffleHeaderProvider);
-      this.expectedResponseSize = headerWriteCount * headerSize;
+    public ShuffleHandlerForKeepAliveTests(long attemptId, ResponseConfig responseConfig) throws IOException {
+      this.shuffleHeaderProvider = new ShuffleHeaderProvider(attemptId);
+      responseConfig.setHeaderSize(shuffleHeaderProvider.getShuffleHeaderSize());
+      this.responseConfig = responseConfig;
+      this.headerPopulator = new HeaderPopulator(this, responseConfig, shuffleHeaderProvider, true);
+      this.mapOutputSender = new MapOutputSender(this, responseConfig, lastSocketAddress, shuffleHeaderProvider);
       setUseOutboundExceptionHandler(true);
     }
 
-    private int getShuffleHeaderSize(ShuffleHeaderProvider shuffleHeaderProvider) throws IOException {
-      DataOutputBuffer dob = new DataOutputBuffer();
-      ShuffleHeader header =
-          shuffleHeaderProvider.createNewShuffleHeader();
-      header.write(dob);
-      return dob.size();
+    public void setFailImmediatelyOnErrors(boolean failImmediatelyOnErrors) {
+      this.failImmediatelyOnErrors = failImmediatelyOnErrors;
+    }
+
+    public void setCloseChannelOnError(boolean closeChannelOnError) {
+      this.closeChannelOnError = closeChannelOnError;
     }
 
     @Override
@@ -261,8 +310,9 @@ protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx,
 
         @Override
         public void channelActive(ChannelHandlerContext ctx) throws Exception {
-          ctx.pipeline().replace(HttpResponseEncoder.class, "loggingResponseEncoder", new LoggingHttpResponseEncoder(false));
+          ctx.pipeline().replace(HttpResponseEncoder.class, ENCODER_HANDLER_NAME, new LoggingHttpResponseEncoder(false));
           replaceTimeoutHandlerWithCustom(ctx);
+          LOG.debug("Modified pipeline: {}", ctx.pipeline());
           super.channelActive(ctx);
         }
 
@@ -278,25 +328,36 @@ private void replaceTimeoutHandlerWithCustom(ChannelHandlerContext ctx) {
         @Override
         protected void sendError(ChannelHandlerContext ctx,
             HttpResponseStatus status) {
-          if (failures.size() == 0) {
-            failures.add(new Error());
-            LOG.warn("sendError: Closing channel");
-            ctx.channel().close();
+          String message = "Error while processing request. Status: " + status;
+          handleError(ctx, message);
+          if (failImmediatelyOnErrors) {
+            stop();
           }
         }
 
         @Override
         protected void sendError(ChannelHandlerContext ctx, String message,
             HttpResponseStatus status) {
-          if (failures.size() == 0) {
-            failures.add(new Error());
-            LOG.warn("sendError: Closing channel");
-            ctx.channel().close();
+          String errMessage = String.format("Error while processing request. " +
+              "Status: " +
+              "%s, message: %s", status, message);
+          handleError(ctx, errMessage);
+          if (failImmediatelyOnErrors) {
+            stop();
           }
         }
       };
     }
 
+    private void handleError(ChannelHandlerContext ctx, String message) {
+      LOG.error(message);
+      failures.add(new Error(message));
+      if (closeChannelOnError) {
+        LOG.warn("sendError: Closing channel");
+        ctx.channel().close();
+      }
+    }
+
     private class CustomTimeoutHandler extends TimeoutHandler {
       private boolean channelIdle = false;
       private final Consumer<IdleStateEvent> channelIdleCallback;
@@ -322,33 +383,35 @@ public void channelIdle(ChannelHandlerContext ctx, IdleStateEvent e) {
 
   private static class MapOutputSender {
     private final ShuffleHandler shuffleHandler;
-    private int headerWriteCount;
+    private ResponseConfig responseConfig;
     private final LastSocketAddress lastSocketAddress;
     private ShuffleHeaderProvider shuffleHeaderProvider;
+    private AdditionalMapOutputSenderOperations additionalMapOutputSenderOperations;
 
     public MapOutputSender(ShuffleHandler shuffleHandler,
-        int headerWriteCount, LastSocketAddress lastSocketAddress,
+        ResponseConfig responseConfig, LastSocketAddress lastSocketAddress,
         ShuffleHeaderProvider shuffleHeaderProvider) {
       this.shuffleHandler = shuffleHandler;
-      this.headerWriteCount = headerWriteCount;
+      this.responseConfig = responseConfig;
       this.lastSocketAddress = lastSocketAddress;
       this.shuffleHeaderProvider = shuffleHeaderProvider;
+      this.additionalMapOutputSenderOperations = null;
     }
 
     public ChannelFuture send(ChannelHandlerContext ctx, Channel ch) throws IOException {
       LOG.debug("In MapOutputSender#send");
       lastSocketAddress.setAddress(ch.remoteAddress());
-      ShuffleHeader header =
-          shuffleHeaderProvider.createNewShuffleHeader();
+      ShuffleHeader header = shuffleHeaderProvider.createNewShuffleHeader();
       writeOneHeader(ch, header);
-      ChannelFuture future = writeHeaderNTimes(ch, header,
-          headerWriteCount);
+      ChannelFuture future = writeHeaderNTimes(ch, header, responseConfig.headerWriteCount);
       // This is the last operation
       // It's safe to increment ShuffleHeader counter for better identification
       shuffleHeaderProvider.incrementCounter();
+      if (additionalMapOutputSenderOperations != null) {
+        return additionalMapOutputSenderOperations.perform(ctx, ch);
+      }
       return future;
     }
-
     private void writeOneHeader(Channel ch, ShuffleHeader header) throws IOException {
       DataOutputBuffer dob = new DataOutputBuffer();
       header.write(dob);
@@ -363,14 +426,14 @@ private ChannelFuture writeHeaderNTimes(Channel ch, ShuffleHeader header, int it
         header.write(dob);
       }
       LOG.debug("MapOutputSender#writeHeaderNTimes WriteAndFlush big chunk of data, outputBufferSize: " + dob.size());
-      return ch.writeAndFlush(wrappedBuffer(dob.getData(), 0,
-          dob.getLength()));
+      return ch.writeAndFlush(wrappedBuffer(dob.getData(), 0, dob.getLength()));
     }
   }
 
   private static class ShuffleHeaderProvider {
     private final long attemptId;
     private final AtomicInteger attemptCounter;
+    private int cachedSize = Integer.MIN_VALUE;
 
     public ShuffleHeaderProvider(long attemptId) {
       this.attemptId = attemptId;
@@ -385,20 +448,31 @@ ShuffleHeader createNewShuffleHeader() {
     void incrementCounter() {
       attemptCounter.incrementAndGet();
     }
+
+    private int getShuffleHeaderSize() throws IOException {
+      if (cachedSize != Integer.MIN_VALUE) {
+        return cachedSize;
+      }
+      DataOutputBuffer dob = new DataOutputBuffer();
+      ShuffleHeader header = createNewShuffleHeader();
+      header.write(dob);
+      cachedSize = dob.size();
+      return cachedSize;
+    }
   }
 
   private static class HeaderPopulator {
     private ShuffleHandler shuffleHandler;
-    private final int headerWriteCount;
+    private ResponseConfig responseConfig;
     private boolean disableKeepAliveConfig;
     private ShuffleHeaderProvider shuffleHeaderProvider;
 
     public HeaderPopulator(ShuffleHandler shuffleHandler,
-        int headerWriteCount,
-        boolean disableKeepAliveConfig,
-        ShuffleHeaderProvider shuffleHeaderProvider) {
+        ResponseConfig responseConfig,
+        ShuffleHeaderProvider shuffleHeaderProvider,
+        boolean disableKeepAliveConfig) {
       this.shuffleHandler = shuffleHandler;
-      this.headerWriteCount = headerWriteCount;
+      this.responseConfig = responseConfig;
       this.disableKeepAliveConfig = disableKeepAliveConfig;
       this.shuffleHeaderProvider = shuffleHeaderProvider;
     }
@@ -406,19 +480,17 @@ public HeaderPopulator(ShuffleHandler shuffleHandler,
     public long populateHeaders(boolean keepAliveParam) throws IOException {
       // Send some dummy data (populate content length details)
       DataOutputBuffer dob = new DataOutputBuffer();
-      for (int i = 0; i < headerWriteCount; ++i) {
+      for (int i = 0; i < responseConfig.headerWriteCount; ++i) {
         ShuffleHeader header =
             shuffleHeaderProvider.createNewShuffleHeader();
         header.write(dob);
       }
-      long contentLength = dob.getLength();
-      LOG.debug("HTTP response content length: {}", contentLength);
       // for testing purpose;
       // disable connectionKeepAliveEnabled if keepAliveParam is available
       if (keepAliveParam && disableKeepAliveConfig) {
         shuffleHandler.connectionKeepAliveEnabled = false;
       }
-      return contentLength;
+      return responseConfig.responseContentLength;
     }
   }
 
@@ -438,7 +510,7 @@ private HttpConnectionData(HttpURLConnection conn, int payloadLength,
       try {
         this.responseCode = conn.getResponseCode();
       } catch (IOException e) {
-        Assert.fail("Failed to read response code from connection: " + conn);
+        fail("Failed to read response code from connection: " + conn);
       }
     }
 
@@ -479,7 +551,14 @@ public HttpConnectionAssert expectKeepAliveWithTimeout(long timeout) {
       return this;
     }
 
-    public HttpConnectionAssert expectResponseSize(int size) {
+    public HttpConnectionAssert expectBadRequest(long timeout) {
+      Assert.assertEquals(HttpURLConnection.HTTP_BAD_REQUEST, connData.responseCode);
+      assertHeaderValue(HttpHeader.CONNECTION, HttpHeader.KEEP_ALIVE.asString());
+      assertHeaderValue(HttpHeader.KEEP_ALIVE, "timeout=" + timeout);
+      return this;
+    }
+
+    public HttpConnectionAssert expectResponseContentLength(long size) {
       Assert.assertEquals(size, connData.payloadLength);
       return this;
     }
@@ -502,7 +581,15 @@ public HttpConnectionHelper(LastSocketAddress lastSocketAddress) {
       this.lastSocketAddress = lastSocketAddress;
     }
 
-    public void connectToUrls(String[] urls) throws IOException {
+    public void connectToUrls(String[] urls, ResponseConfig responseConfig) throws IOException {
+      connectToUrlsInternal(urls, responseConfig, HttpURLConnection.HTTP_OK);
+    }
+
+    public void connectToUrls(String[] urls, ResponseConfig responseConfig, int expectedHttpStatus) throws IOException {
+      connectToUrlsInternal(urls, responseConfig, expectedHttpStatus);
+    }
+
+    private void connectToUrlsInternal(String[] urls, ResponseConfig responseConfig, int expectedHttpStatus) throws IOException {
       int requests = urls.length;
       LOG.debug("Will connect to URLs: {}", Arrays.toString(urls));
       for (int reqIdx = 0; reqIdx < requests; reqIdx++) {
@@ -514,15 +601,35 @@ public void connectToUrls(String[] urls) throws IOException {
             ShuffleHeader.DEFAULT_HTTP_HEADER_NAME);
         conn.setRequestProperty(ShuffleHeader.HTTP_HEADER_VERSION,
             ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION);
+        TEST_EXECUTION.parameterizeConnection(conn);
         conn.connect();
+        if (expectedHttpStatus == HttpURLConnection.HTTP_BAD_REQUEST) {
+          //Catch exception as error are caught with overridden sendError method
+          //This will be validated later
+          try {
+            DataInputStream input = new DataInputStream(conn.getInputStream());
+          } catch (Exception e) {
+            return;
+          }
+        }
         DataInputStream input = new DataInputStream(conn.getInputStream());
         LOG.debug("Opened DataInputStream for connection: {}/{}", (reqIdx + 1), requests);
         ShuffleHeader header = new ShuffleHeader();
         header.readFields(input);
         InputStreamReadResult result = readDataFromInputStream(input);
+        result.totalBytesRead += responseConfig.headerSize;
+        int expectedContentLength =
+            Integer.parseInt(conn.getHeaderField(HttpHeader.CONTENT_LENGTH.asString()));
+        
+        if (result.totalBytesRead < expectedContentLength) {
+          throw new IOException(String.format("Premature EOF inputStream. " +
+              "Expected content-length: %s, " +
+              "Actual content-length: %s", expectedContentLength, result.totalBytesRead));
+        }
         connectionData.add(HttpConnectionData
             .create(conn, result.totalBytesRead, lastSocketAddress.getSocketAddres()));
         input.close();
+        LOG.debug("Finished all interactions with URL: {}. Progress: {}/{}", url, (reqIdx + 1), requests);
       }
 
       Assert.assertEquals(urls.length, connectionData.size());
@@ -541,7 +648,7 @@ HttpConnectionData getConnectionData(int i) {
     }
 
     private static InputStreamReadResult readDataFromInputStream(
-        DataInputStream input) throws IOException {
+        InputStream input) throws IOException {
       ByteArrayOutputStream dataStream = new ByteArrayOutputStream();
       byte[] buffer = new byte[1024];
       int bytesRead;
@@ -741,7 +848,7 @@ private static boolean isPortUsed(int port) {
     try (Socket ignored = new Socket("localhost", port)) {
       return true;
     } catch (IOException e) {
-      LOG.debug("Port test result: {}", e.getMessage());
+      LOG.error("Port: {}, port check result: {}", port, e.getMessage());
       return false;
     }
   }
@@ -891,8 +998,7 @@ protected void sendError(ChannelHandlerContext ctx, String message,
     header.readFields(input);
     input.close();
 
-    assertEquals("sendError called when client closed connection", 0,
-        failures.size());
+    assertEquals("sendError called when client closed connection", 0, failures.size());
     Assert.assertEquals("Should have no caught exceptions",
         new ArrayList<>(), failures);
 
@@ -915,7 +1021,22 @@ public void testKeepAliveInitiallyEnabled() throws Exception {
     conf.setInt(ShuffleHandler.SHUFFLE_PORT_CONFIG_KEY, TEST_EXECUTION.shuffleHandlerPort());
     conf.setBoolean(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_ENABLED, true);
     conf.setInt(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_TIME_OUT, TEST_EXECUTION.getKeepAliveTimeout());
-    testKeepAliveInternal(conf, ShuffleUrlType.SIMPLE, ShuffleUrlType.WITH_KEEPALIVE);
+    ResponseConfig responseConfig = new ResponseConfig(HEADER_WRITE_COUNT, 1,
+        0);
+    ShuffleHandlerForKeepAliveTests shuffleHandler = new ShuffleHandlerForKeepAliveTests(ATTEMPT_ID, responseConfig);
+    testKeepAliveWithHttpOk(conf, shuffleHandler, ShuffleUrlType.SIMPLE, ShuffleUrlType.WITH_KEEPALIVE);
+  }
+
+  @Test(timeout = 1000000)
+  public void testKeepAliveInitiallyEnabled2() throws Exception {
+    Configuration conf = new Configuration();
+    conf.setInt(ShuffleHandler.SHUFFLE_PORT_CONFIG_KEY, TEST_EXECUTION.shuffleHandlerPort());
+    conf.setBoolean(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_ENABLED, true);
+    conf.setInt(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_TIME_OUT, TEST_EXECUTION.getKeepAliveTimeout());
+    ResponseConfig responseConfig = new ResponseConfig(HEADER_WRITE_COUNT, 1,
+        0);
+    ShuffleHandlerForKeepAliveTests shuffleHandler = new ShuffleHandlerForKeepAliveTests(ATTEMPT_ID, responseConfig);
+    testKeepAliveWithHttpOk(conf, shuffleHandler, ShuffleUrlType.WITH_KEEPALIVE, ShuffleUrlType.WITH_KEEPALIVE);
   }
 
   //TODO snemeth implement keepalive test that used properly mocked ShuffleHandler
@@ -925,39 +1046,126 @@ public void testKeepAliveInitiallyDisabled() throws Exception {
     conf.setInt(ShuffleHandler.SHUFFLE_PORT_CONFIG_KEY, TEST_EXECUTION.shuffleHandlerPort());
     conf.setBoolean(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_ENABLED, false);
     conf.setInt(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_TIME_OUT, TEST_EXECUTION.getKeepAliveTimeout());
-    testKeepAliveInternal(conf, ShuffleUrlType.WITH_KEEPALIVE, ShuffleUrlType.WITH_KEEPALIVE);
+    ResponseConfig responseConfig = new ResponseConfig(HEADER_WRITE_COUNT, 1,
+        0);
+    ShuffleHandlerForKeepAliveTests shuffleHandler = new ShuffleHandlerForKeepAliveTests(ATTEMPT_ID, responseConfig);
+    testKeepAliveWithHttpOk(conf, shuffleHandler, ShuffleUrlType.WITH_KEEPALIVE, ShuffleUrlType.WITH_KEEPALIVE);
+  }
+
+  @Test(timeout = 10000)
+  public void testKeepAliveMultipleMapAttemptIds() throws Exception {
+    final int mapOutputContentLength = 11;
+    final int mapOutputCount = 2;
+    
+    Configuration conf = new Configuration();
+    conf.setInt(ShuffleHandler.SHUFFLE_PORT_CONFIG_KEY, TEST_EXECUTION.shuffleHandlerPort());
+    conf.setBoolean(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_ENABLED, true);
+    conf.setInt(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_TIME_OUT, TEST_EXECUTION.getKeepAliveTimeout());
+    ResponseConfig responseConfig = new ResponseConfig(HEADER_WRITE_COUNT,
+        mapOutputCount, mapOutputContentLength);
+    ShuffleHandlerForKeepAliveTests shuffleHandler = new ShuffleHandlerForKeepAliveTests(ATTEMPT_ID, responseConfig);
+    shuffleHandler.mapOutputSender.additionalMapOutputSenderOperations = new AdditionalMapOutputSenderOperations() {
+      @Override
+      public ChannelFuture perform(ChannelHandlerContext ctx, Channel ch) throws IOException {
+        File tmpFile = File.createTempFile("test", ".tmp");
+        Files.write(tmpFile.toPath(), "dummytestcontent123456".getBytes(StandardCharsets.UTF_8));
+        final DefaultFileRegion partition = new DefaultFileRegion(tmpFile, 0, mapOutputContentLength);
+        LOG.debug("Writing response partition: {}, channel: {}", partition,
+            ch.id());
+        return ch.writeAndFlush(partition)
+            .addListener((ChannelFutureListener) future ->
+                LOG.debug("Finished Writing response partition: {}, channel: " +
+                    "{}", partition, ch.id()));
+      }
+    };
+    testKeepAliveWithHttpOk(conf, shuffleHandler, 
+        ShuffleUrlType.WITH_KEEPALIVE_MULTIPLE_MAP_IDS, 
+        ShuffleUrlType.WITH_KEEPALIVE_MULTIPLE_MAP_IDS);
+  }
+
+  @Test(timeout = 10000)
+  public void testKeepAliveWithoutMapAttemptIds() throws Exception {
+    Configuration conf = new Configuration();
+    conf.setInt(ShuffleHandler.SHUFFLE_PORT_CONFIG_KEY, TEST_EXECUTION.shuffleHandlerPort());
+    conf.setBoolean(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_ENABLED, true);
+    conf.setInt(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_TIME_OUT, TEST_EXECUTION.getKeepAliveTimeout());
+    ResponseConfig responseConfig = new ResponseConfig(HEADER_WRITE_COUNT, 1, 0);
+    ShuffleHandlerForKeepAliveTests shuffleHandler = new ShuffleHandlerForKeepAliveTests(ATTEMPT_ID, responseConfig);
+    shuffleHandler.setFailImmediatelyOnErrors(true);
+    //Closing channels caused Netty to open another channel 
+    // so 1 request was handled with 2 separate channels, 
+    // ultimately generating 2 * HTTP 400 errors.
+    // We'd like to avoid this so disabling close channel here.
+    shuffleHandler.setCloseChannelOnError(false);
+    testKeepAliveWithHttpBadRequest(conf, shuffleHandler, 1, ShuffleUrlType.WITH_KEEPALIVE_NO_MAP_IDS);
   }
-  private void testKeepAliveInternal(Configuration conf, ShuffleUrlType... shuffleUrlTypes) throws IOException {
-    Assert.assertTrue("Expected at least two shuffle URL types ",
-        shuffleUrlTypes.length >= 2);
-    ShuffleHandlerForKeepAliveTests shuffleHandler = new ShuffleHandlerForKeepAliveTests(HEADER_WRITE_COUNT, ATTEMPT_ID);
+  
+  private void testKeepAliveWithHttpOk(
+      Configuration conf,
+      ShuffleHandlerForKeepAliveTests shuffleHandler,
+      ShuffleUrlType... shuffleUrlTypes) throws IOException {
+    testKeepAliveWithHttpStatus(conf, shuffleHandler, shuffleUrlTypes, HttpURLConnection.HTTP_OK);
+  }
+
+  private void testKeepAliveWithHttpBadRequest(
+      Configuration conf,
+      ShuffleHandlerForKeepAliveTests shuffleHandler,
+      int mapOutputCount,
+      ShuffleUrlType... shuffleUrlTypes) throws IOException {
+    testKeepAliveWithHttpStatus(conf, shuffleHandler, shuffleUrlTypes, HttpURLConnection.HTTP_BAD_REQUEST);
+  }
+
+  private void testKeepAliveWithHttpStatus(Configuration conf,
+      ShuffleHandlerForKeepAliveTests shuffleHandler,
+      ShuffleUrlType[] shuffleUrlTypes, 
+      int expectedHttpStatus
+      ) throws IOException {
+    if (expectedHttpStatus != HttpURLConnection.HTTP_BAD_REQUEST) {
+      Assert.assertTrue("Expected at least two shuffle URL types ",
+          shuffleUrlTypes.length >= 2);
+    }
     shuffleHandler.init(conf);
     shuffleHandler.start();
 
     String[] urls = new String[shuffleUrlTypes.length];
     for (int i = 0; i < shuffleUrlTypes.length; i++) {
-      if (shuffleUrlTypes[i] == ShuffleUrlType.SIMPLE) {
+      ShuffleUrlType url = shuffleUrlTypes[i];
+      if (url == ShuffleUrlType.SIMPLE) {
         urls[i] = getShuffleUrl(shuffleHandler, ATTEMPT_ID, ATTEMPT_ID);
-      } else if (shuffleUrlTypes[i] == ShuffleUrlType.WITH_KEEPALIVE) {
+      } else if (url == ShuffleUrlType.WITH_KEEPALIVE) {
         urls[i] = getShuffleUrlWithKeepAlive(shuffleHandler, ATTEMPT_ID, ATTEMPT_ID);
+      } else if (url == ShuffleUrlType.WITH_KEEPALIVE_MULTIPLE_MAP_IDS) {
+        urls[i] = getShuffleUrlWithKeepAlive(shuffleHandler, ATTEMPT_ID, ATTEMPT_ID, ATTEMPT_ID_2);
+      } else if (url == ShuffleUrlType.WITH_KEEPALIVE_NO_MAP_IDS) {
+        urls[i] = getShuffleUrlWithKeepAlive(shuffleHandler, ATTEMPT_ID);
       }
     }
+    HttpConnectionHelper connHelper;
+    try {
+      connHelper = new HttpConnectionHelper(shuffleHandler.lastSocketAddress);
+      connHelper.connectToUrls(urls, shuffleHandler.responseConfig, expectedHttpStatus);
+      if (expectedHttpStatus == HttpURLConnection.HTTP_BAD_REQUEST) {
+        Assert.assertEquals(1, shuffleHandler.failures.size());
+        Assert.assertThat(shuffleHandler.failures.get(0).getMessage(),
+            CoreMatchers.containsString("Status: 400 Bad Request, message: Required param job, map and reduce"));
+      }
+    } finally {
+      shuffleHandler.stop();
+    }
 
-    HttpConnectionHelper httpConnectionHelper = new HttpConnectionHelper(shuffleHandler.lastSocketAddress);
-    httpConnectionHelper.connectToUrls(urls);
-
-    //Expectations
+    //Verify expectations
     int configuredTimeout = TEST_EXECUTION.getKeepAliveTimeout();
     int expectedTimeout = configuredTimeout < 0 ? 1 : configuredTimeout;
-    httpConnectionHelper.validate(connData -> {
-      HttpConnectionAssert.create(connData)
-          .expectKeepAliveWithTimeout(expectedTimeout)
-          .expectResponseSize(shuffleHandler.expectedResponseSize);
-    });
-    HttpConnectionAssert.assertKeepAliveConnectionsAreSame(httpConnectionHelper);
-    Assert.assertEquals("Unexpected failure", new ArrayList<>(), shuffleHandler.failures);
 
-    shuffleHandler.stop();
+    connHelper.validate(connData -> {
+        HttpConnectionAssert.create(connData)
+            .expectKeepAliveWithTimeout(expectedTimeout)
+            .expectResponseContentLength(shuffleHandler.responseConfig.responseContentLength);
+    });
+    if (expectedHttpStatus == HttpURLConnection.HTTP_OK) {
+      HttpConnectionAssert.assertKeepAliveConnectionsAreSame(connHelper);
+      Assert.assertEquals("Unexpected ShuffleHandler failure", new ArrayList<>(), shuffleHandler.failures);
+    }
   }
 
   @Test(timeout = 10000)
@@ -1138,9 +1346,9 @@ public void exceptionCaught(ChannelHandlerContext ctx,
       } catch (IOException ioe) {
         LOG.info("Expected - connection should not be open");
       } catch (NumberFormatException ne) {
-        Assert.fail("Expected a numerical value for RETRY_AFTER header field");
+        fail("Expected a numerical value for RETRY_AFTER header field");
       } catch (Exception e) {
-        Assert.fail("Expected a IOException");
+        fail("Expected a IOException");
       }
       int statusCode = conn.getResponseCode();
       LOG.debug("Connection status code: {}", statusCode);
@@ -1238,6 +1446,7 @@ public void channelActive(ChannelHandlerContext ctx) throws Exception {
             ctx.pipeline().replace(HttpResponseEncoder.class, 
                 "loggingResponseEncoder",
                 new LoggingHttpResponseEncoder(false));
+            LOG.debug("Modified pipeline: {}", ctx.pipeline());
             super.channelActive(ctx);
           }
         };
@@ -1501,7 +1710,7 @@ public void testRecoveryFromOtherVersions() throws IOException {
     
       try {
         shuffle.start();
-        Assert.fail("Incompatible version, should expect fail here.");
+        fail("Incompatible version, should expect fail here.");
       } catch (ServiceStateException e) {
         Assert.assertTrue("Exception message mismatch", 
         e.getMessage().contains("Incompatible version for state DB schema:"));
@@ -1703,18 +1912,29 @@ public void testIdleStateHandlingNegativeTimeoutDefaultsTo1Second() throws Excep
     testHandlingIdleState(timeoutSeconds, expectedTimeoutSeconds);
   }
 
-  private String getShuffleUrlWithKeepAlive(ShuffleHandler shuffleHandler, long jobId, long attemptId) {
-    String url = getShuffleUrl(shuffleHandler, jobId, attemptId);
+  private String getShuffleUrlWithKeepAlive(ShuffleHandler shuffleHandler, long jobId, long... attemptIds) {
+    String url = getShuffleUrl(shuffleHandler, jobId, attemptIds);
     return url + "&keepAlive=true";
   }
 
-  private String getShuffleUrl(ShuffleHandler shuffleHandler, long jobId, long attemptId) {
+  private String getShuffleUrl(ShuffleHandler shuffleHandler, long jobId, long... attemptIds) {
     String port = shuffleHandler.getConfig().get(ShuffleHandler.SHUFFLE_PORT_CONFIG_KEY);
     String shuffleBaseURL = "http://127.0.0.1:" + port;
+
+    StringBuilder mapAttemptIds = new StringBuilder();
+    for (int i = 0; i < attemptIds.length; i++) {
+      if (i == 0) {
+        mapAttemptIds.append("&map=");
+      } else {
+        mapAttemptIds.append(",");
+      }
+      mapAttemptIds.append(String.format("attempt_%s_1_m_1_0", attemptIds[i]));
+    }
+    
     String location = String.format("/mapOutput" +
         "?job=job_%s_1" +
         "&reduce=1" +
-        "&map=attempt_%s_1_m_1_0", jobId, attemptId);
+        "%s", jobId, mapAttemptIds.toString());
     return shuffleBaseURL + location;
   }
 
@@ -1726,9 +1946,9 @@ private void testHandlingIdleState(int configuredTimeoutSeconds, int expectedTim
     conf.setInt(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_TIME_OUT, configuredTimeoutSeconds);
 
     final CountDownLatch countdownLatch = new CountDownLatch(1);
-    ShuffleHandlerForKeepAliveTests shuffleHandler = new ShuffleHandlerForKeepAliveTests(HEADER_WRITE_COUNT, ATTEMPT_ID, event -> {
-      countdownLatch.countDown();
-    });
+    ResponseConfig responseConfig = new ResponseConfig(HEADER_WRITE_COUNT, 1, 0);
+    ShuffleHandlerForKeepAliveTests shuffleHandler = new ShuffleHandlerForKeepAliveTests(ATTEMPT_ID, responseConfig,
+        event -> countdownLatch.countDown());
     shuffleHandler.init(conf);
     shuffleHandler.start();
 
@@ -1736,7 +1956,7 @@ private void testHandlingIdleState(int configuredTimeoutSeconds, int expectedTim
     String[] urls = new String[] {shuffleUrl};
     HttpConnectionHelper httpConnectionHelper = new HttpConnectionHelper(shuffleHandler.lastSocketAddress);
     long beforeConnectionTimestamp = System.currentTimeMillis();
-    httpConnectionHelper.connectToUrls(urls);
+    httpConnectionHelper.connectToUrls(urls, shuffleHandler.responseConfig);
     countdownLatch.await();
     long channelClosedTimestamp = System.currentTimeMillis();
     long secondsPassed =
