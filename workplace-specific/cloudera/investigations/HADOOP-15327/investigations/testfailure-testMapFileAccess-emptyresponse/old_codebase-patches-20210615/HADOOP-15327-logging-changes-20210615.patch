Index: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java
--- a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java	
+++ b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java	
@@ -95,8 +95,10 @@
 import org.iq80.leveldb.DBException;
 import org.iq80.leveldb.Options;
 import org.jboss.netty.bootstrap.ServerBootstrap;
+import org.jboss.netty.buffer.ChannelBuffer;
 import org.jboss.netty.buffer.ChannelBuffers;
 import org.jboss.netty.channel.Channel;
+import org.jboss.netty.channel.ChannelEvent;
 import org.jboss.netty.channel.ChannelFactory;
 import org.jboss.netty.channel.ChannelFuture;
 import org.jboss.netty.channel.ChannelFutureListener;
@@ -115,6 +117,7 @@
 import org.jboss.netty.handler.codec.frame.TooLongFrameException;
 import org.jboss.netty.handler.codec.http.DefaultHttpResponse;
 import org.jboss.netty.handler.codec.http.HttpChunkAggregator;
+import org.jboss.netty.handler.codec.http.HttpMessage;
 import org.jboss.netty.handler.codec.http.HttpRequest;
 import org.jboss.netty.handler.codec.http.HttpRequestDecoder;
 import org.jboss.netty.handler.codec.http.HttpResponse;
@@ -304,7 +307,9 @@
 
     @Override
     public void operationComplete(ChannelFuture future) throws Exception {
+      LOG.info("***Operationcomplete");
       if (!future.isSuccess()) {
+        LOG.error("***Closing channel");
         future.getChannel().close();
         return;
       }
@@ -318,6 +323,7 @@
               (TimeoutHandler)pipeline.get(TIMEOUT_HANDLER);
           timeoutHandler.setEnabledTimeout(true);
         } else {
+          LOG.error("***Closing channel");
           future.getChannel().close();
         }
       } else {
@@ -796,6 +802,7 @@
     @Override
     public void channelIdle(ChannelHandlerContext ctx, IdleStateEvent e) {
       if (e.getState() == IdleState.WRITER_IDLE && enabledTimeout) {
+        LOG.debug("***Closing channel as writer was idle");
         e.getChannel().close();
       }
     }
@@ -836,7 +843,75 @@
       }
       pipeline.addLast("decoder", new HttpRequestDecoder());
       pipeline.addLast("aggregator", new HttpChunkAggregator(1 << 16));
-      pipeline.addLast("encoder", new HttpResponseEncoder());
+      pipeline.addLast("encoder", new HttpResponseEncoder() {
+        @Override
+        protected void encodeInitialLine(ChannelBuffer buf, HttpMessage message) throws Exception {
+          LOG.debug("***HttpResponseEncoder#encodeInitialLine");
+          super.encodeInitialLine(buf, message);
+        }
+
+        @Override
+        protected Object encode(ChannelHandlerContext ctx, Channel channel,
+            Object msg) throws Exception {
+          LOG.debug("***HttpResponseEncoder#encode");
+          return super.encode(ctx, channel, msg);
+        }
+
+        @Override
+        public void handleDownstream(ChannelHandlerContext ctx,
+            ChannelEvent evt) throws Exception {
+          super.handleDownstream(ctx, evt);
+        }
+
+        @Override
+        protected boolean doEncode(ChannelHandlerContext ctx, MessageEvent e) throws Exception {
+          LOG.debug("***HttpResponseEncoder#doEncode");
+          return super.doEncode(ctx, e);
+        }
+        //        @Override
+//        public boolean acceptOutboundMessage(Object msg) throws Exception {
+//          LOG.debug("***HttpResponseEncoder#acceptOutboundMessage");
+//          return super.acceptOutboundMessage(msg);
+//        }
+//
+//        @Override
+//        protected void encodeInitialLine(ByteBuf buf, HttpResponse response) throws Exception {
+//          LOG.debug("***HttpResponseEncoder#encodeInitialLine: " + response);
+//          super.encodeInitialLine(buf, response);
+//        }
+//
+//        @Override
+//        protected void sanitizeHeadersBeforeEncode(HttpResponse msg,
+//            boolean isAlwaysEmpty) {
+//          LOG.debug("***HttpResponseEncoder#sanitizeHeadersBeforeEncode");
+//          super.sanitizeHeadersBeforeEncode(msg, isAlwaysEmpty);
+//        }
+//
+//        @Override
+//        protected boolean isContentAlwaysEmpty(HttpResponse msg) {
+//          LOG.debug("***HttpResponseEncoder#isContentAlwaysEmpty");
+//          return super.isContentAlwaysEmpty(msg);
+//        }
+//
+//        @Override
+//        protected void encode(ChannelHandlerContext ctx, Object msg,
+//            List<Object> out) throws Exception {
+//          LOG.debug("***HttpResponseEncoder#encode");
+//          super.encode(ctx, msg, out);
+//        }
+//
+//        @Override
+//        protected void encodeHeaders(HttpHeaders headers, ByteBuf buf) {
+//          LOG.debug("***HttpResponseEncoder#encodeHeaders");
+//          super.encodeHeaders(headers, buf);
+//        }
+//
+//        @Override
+//        public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception {
+//          LOG.debug("***HttpResponseEncoder#write");
+//          super.write(ctx, msg, promise);
+//        }
+      });
       pipeline.addLast("chunking", new ChunkedWriteHandler());
       pipeline.addLast("shuffle", SHUFFLE);
       pipeline.addLast("idle", idleStateHandler);
@@ -906,6 +981,7 @@
     @Override
     public void channelOpen(ChannelHandlerContext ctx, ChannelStateEvent evt) 
         throws Exception {
+      LOG.debug("***channelActive");
       super.channelOpen(ctx, evt);
 
       if ((maxShuffleConnections > 0) && (accepted.size() >= maxShuffleConnections)) {
@@ -928,6 +1004,7 @@
     @Override
     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)
         throws Exception {
+      LOG.debug("***channelRead");
       HttpRequest request = (HttpRequest) evt.getMessage();
       if (request.getMethod() != GET) {
           sendError(ctx, METHOD_NOT_ALLOWED);
@@ -1021,11 +1098,13 @@
         sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);
         return;
       }
+      LOG.debug("***written response: " + response);
       ch.write(response);
       //Initialize one ReduceContext object per messageReceived call
       boolean keepAlive = keepAliveParam || connectionKeepAliveEnabled;
       ReduceContext reduceContext = new ReduceContext(mapIds, reduceId, ctx,
           user, mapOutputInfoMap, jobId, keepAlive);
+      LOG.debug("***After response");
       for (int i = 0; i < Math.min(maxSessionOpenFiles, mapIds.size()); i++) {
         ChannelFuture nextMap = sendMap(reduceContext);
         if(nextMap == null) {
@@ -1059,6 +1138,7 @@
             info = getMapOutputInfo(mapId, reduceContext.getReduceId(),
                 reduceContext.getJobId(), reduceContext.getUser());
           }
+          LOG.debug("***before sendMapOutput");
           nextMap = sendMapOutput(
               reduceContext.getCtx(),
               reduceContext.getCtx().getChannel(),
Index: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/java/org/apache/hadoop/mapred/TestShuffleHandler.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/java/org/apache/hadoop/mapred/TestShuffleHandler.java b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/java/org/apache/hadoop/mapred/TestShuffleHandler.java
--- a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/java/org/apache/hadoop/mapred/TestShuffleHandler.java	
+++ b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/java/org/apache/hadoop/mapred/TestShuffleHandler.java	
@@ -45,6 +45,7 @@
 import java.util.Arrays;
 import java.util.List;
 import java.util.Map;
+import java.util.concurrent.atomic.AtomicInteger;
 import java.util.zip.CheckedOutputStream;
 import java.util.zip.Checksum;
 
@@ -81,6 +82,7 @@
 import org.apache.hadoop.yarn.server.records.Version;
 import org.jboss.netty.channel.Channel;
 import org.jboss.netty.channel.ChannelFuture;
+import org.jboss.netty.channel.ChannelFutureListener;
 import org.jboss.netty.channel.ChannelHandlerContext;
 import org.jboss.netty.channel.ChannelPipeline;
 import org.jboss.netty.channel.socket.SocketChannel;
@@ -362,11 +364,11 @@
     }
   }
 
-  @Test(timeout = 10000)
+  @Test(timeout = 150000)
   public void testKeepAlive() throws Exception {
     final ArrayList<Throwable> failures = new ArrayList<Throwable>(1);
     Configuration conf = new Configuration();
-    conf.setInt(ShuffleHandler.SHUFFLE_PORT_CONFIG_KEY, 0);
+    conf.setInt(ShuffleHandler.SHUFFLE_PORT_CONFIG_KEY, 8088);
     conf.setBoolean(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_ENABLED, true);
     // try setting to -ve keep alive timeout.
     conf.setInt(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_TIME_OUT, -100);
@@ -375,6 +377,7 @@
     ShuffleHandler shuffleHandler = new ShuffleHandler() {
       @Override
       protected Shuffle getShuffle(final Configuration conf) {
+        AtomicInteger counter = new AtomicInteger();
         // replace the shuffle handler with one stubbed for testing
         return new Shuffle(conf) {
           @Override
@@ -395,7 +398,7 @@
               Map<String, MapOutputInfo> infoMap) throws IOException {
             // Send some dummy data (populate content length details)
             ShuffleHeader header =
-                new ShuffleHeader("attempt_12345_1_m_1_0", 5678, 5678, 1);
+                new ShuffleHeader("attempt_12345_1_m_1_0" + counter.get(), 5678, 5678, 1);
             DataOutputBuffer dob = new DataOutputBuffer();
             header.write(dob);
             dob = new DataOutputBuffer();
@@ -417,21 +420,35 @@
           protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx,
               Channel ch, String user, String mapId, int reduce,
               MapOutputInfo info) throws IOException {
+            LOG.debug("***in sendMapOutput");
+            counter.incrementAndGet();
             lastSocketAddress.setAddress(ch.getRemoteAddress());
             HttpResponse response = new DefaultHttpResponse(HTTP_1_1, OK);
 
             // send a shuffle header and a lot of data down the channel
             // to trigger a broken pipe
             ShuffleHeader header =
-                new ShuffleHeader("attempt_12345_1_m_1_0", 5678, 5678, 1);
+                new ShuffleHeader("attempt_12345_1_m_1_0" + counter.get(), 5678, 5678, 1);
             DataOutputBuffer dob = new DataOutputBuffer();
             header.write(dob);
+            LOG.debug("***sendMapOutput before WriteAndFlush #1");
             ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));
+            LOG.debug("***sendMapOutput after WriteAndFlush #1. dob: " + dob.size());
             dob = new DataOutputBuffer();
+            LOG.debug("***created new DOB");
             for (int i = 0; i < 100000; ++i) {
               header.write(dob);
             }
-            return ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));
+            LOG.debug("***sendMapOutput WriteAndFlush big chunk of data");
+            ChannelFuture f = ch.write(wrappedBuffer(dob.getData(), 0,
+                dob.getLength()));
+            f.addListener(new ChannelFutureListener() {
+              @Override
+              public void operationComplete(ChannelFuture future) throws Exception {
+                LOG.info("***Send completed!");
+              }
+            });
+            return f;
           }
 
           @Override
@@ -439,6 +456,7 @@
               HttpResponseStatus status) {
             if (failures.size() == 0) {
               failures.add(new Error());
+              LOG.error("***sendError Closing channel");
               ctx.getChannel().close();
             }
           }
@@ -448,6 +466,7 @@
               HttpResponseStatus status) {
             if (failures.size() == 0) {
               failures.add(new Error());
+              LOG.error("***sendError2 Closing channel");
               ctx.getChannel().close();
             }
           }
@@ -470,6 +489,7 @@
         ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION);
     conn.connect();
     DataInputStream input = new DataInputStream(conn.getInputStream());
+    LOG.debug("***Received DataInputStream #1");
     Assert.assertEquals(HttpHeader.KEEP_ALIVE.asString(),
         conn.getHeaderField(HttpHeader.CONNECTION.asString()));
     Assert.assertEquals("timeout=1",
@@ -478,7 +498,12 @@
     ShuffleHeader header = new ShuffleHeader();
     header.readFields(input);
     byte[] buffer = new byte[1024];
-    while (input.read(buffer) != -1) {}
+    int sumReadBytes = 0;
+    int read = 0;
+    while ((read = input.read(buffer)) != -1) {
+      sumReadBytes += read;
+    }
+    LOG.debug("***Read bytes: " + sumReadBytes);
     SocketAddress firstAddress = lastSocketAddress.getSocketAddres();
     input.close();
 
@@ -493,6 +518,7 @@
         ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION);
     conn.connect();
     input = new DataInputStream(conn.getInputStream());
+    LOG.debug("***Received DataInputStream #2");
     Assert.assertEquals(HttpHeader.KEEP_ALIVE.asString(),
         conn.getHeaderField(HttpHeader.CONNECTION.asString()));
     Assert.assertEquals("timeout=1",
@@ -500,6 +526,13 @@
     Assert.assertEquals(HttpURLConnection.HTTP_OK, conn.getResponseCode());
     header = new ShuffleHeader();
     header.readFields(input);
+    buffer = new byte[1024];
+    sumReadBytes = 0;
+    read = 0;
+    while ((read = input.read(buffer)) != -1) {
+      sumReadBytes += read;
+    }
+    LOG.debug("***Read bytes: " + sumReadBytes);
     input.close();
     SocketAddress secondAddress = lastSocketAddress.getSocketAddres();
     Assert.assertNotNull("Initial shuffle address should not be null",
Index: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/resources/log4j.properties
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/resources/log4j.properties b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/resources/log4j.properties
--- a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/resources/log4j.properties	
+++ b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/resources/log4j.properties	
@@ -12,8 +12,10 @@
 
 # log4j configuration used during build and unit tests
 
-log4j.rootLogger=info,stdout
+log4j.rootLogger=debug,stdout
 log4j.threshold=ALL
 log4j.appender.stdout=org.apache.log4j.ConsoleAppender
 log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
 log4j.appender.stdout.layout.ConversionPattern=%d{ISO8601} %-5p [%t] %c{2} (%F:%M(%L)) - %m%n
+log4j.logger.io.netty=DEBUG
+log4j.logger.org.apache.hadoop.mapred=DEBUG
\ No newline at end of file
