Index: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/java/org/apache/hadoop/mapred/TestShuffleHandler.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/java/org/apache/hadoop/mapred/TestShuffleHandler.java b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/java/org/apache/hadoop/mapred/TestShuffleHandler.java
--- a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/java/org/apache/hadoop/mapred/TestShuffleHandler.java	(revision d4e6956e71f07efdf8401e908ac87e4d0dda1c19)
+++ b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/test/java/org/apache/hadoop/mapred/TestShuffleHandler.java	(date 1624396774047)
@@ -53,6 +53,7 @@
 import java.io.FileInputStream;
 import java.io.FileOutputStream;
 import java.io.IOException;
+import java.io.InputStream;
 import java.net.HttpURLConnection;
 import java.net.InetSocketAddress;
 import java.net.Proxy;
@@ -62,6 +63,7 @@
 import java.nio.ByteBuffer;
 import java.nio.channels.ClosedChannelException;
 import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
@@ -125,10 +127,11 @@
   private static final File ABS_LOG_DIR = GenericTestUtils.getTestDir(
       TestShuffleHandler.class.getSimpleName() + "LocDir");
   private static final long ATTEMPT_ID = 12345L;
+  private static final long ATTEMPT_ID_2 = 12346L;
   
 
   //Control test execution properties with these flags
-  private static final boolean DEBUG_MODE = false;
+  private static final boolean DEBUG_MODE = true;
   //If this is set to true and proxy server is not running, tests will fail!
   private static final boolean USE_PROXY = false; 
   private static final int HEADER_WRITE_COUNT = 100000;
@@ -178,7 +181,7 @@
   }
   
   private enum ShuffleUrlType {
-    SIMPLE, WITH_KEEPALIVE
+    SIMPLE, WITH_KEEPALIVE, WITH_KEEPALIVE_MULTIPLE_MAP_IDS
   }
 
   private static class InputStreamReadResult {
@@ -191,13 +194,19 @@
     }
   }
 
+  private static class AdditionalMapOutputSenderOperations {
+    public void perform(ChannelHandlerContext ctx, Channel ch) throws IOException {
+      
+    }
+  }
+
   private class ShuffleHandlerForKeepAliveTests extends ShuffleHandler {
     final int headerWriteCount;
     final LastSocketAddress lastSocketAddress = new LastSocketAddress();
     final ArrayList<Throwable> failures = new ArrayList<>();
     final ShuffleHeaderProvider shuffleHeaderProvider;
     final HeaderPopulator headerPopulator;
-    final MapOutputSender mapOutputSender;
+    MapOutputSender mapOutputSender;
     private final int expectedResponseSize;
     private Consumer<IdleStateEvent> channelIdleCallback;
     private CustomTimeoutHandler customTimeoutHandler;
@@ -325,6 +334,7 @@
     private int headerWriteCount;
     private final LastSocketAddress lastSocketAddress;
     private ShuffleHeaderProvider shuffleHeaderProvider;
+    private AdditionalMapOutputSenderOperations additionalMapOutputSenderOperations;
 
     public MapOutputSender(ShuffleHandler shuffleHandler,
         int headerWriteCount, LastSocketAddress lastSocketAddress,
@@ -333,6 +343,7 @@
       this.headerWriteCount = headerWriteCount;
       this.lastSocketAddress = lastSocketAddress;
       this.shuffleHeaderProvider = shuffleHeaderProvider;
+      this.additionalMapOutputSenderOperations = new AdditionalMapOutputSenderOperations();
     }
 
     public ChannelFuture send(ChannelHandlerContext ctx, Channel ch) throws IOException {
@@ -346,9 +357,9 @@
       // This is the last operation
       // It's safe to increment ShuffleHeader counter for better identification
       shuffleHeaderProvider.incrementCounter();
+      additionalMapOutputSenderOperations.perform(ctx, ch);
       return future;
     }
-
     private void writeOneHeader(Channel ch, ShuffleHeader header) throws IOException {
       DataOutputBuffer dob = new DataOutputBuffer();
       header.write(dob);
@@ -541,7 +552,7 @@
     }
 
     private static InputStreamReadResult readDataFromInputStream(
-        DataInputStream input) throws IOException {
+        InputStream input) throws IOException {
       ByteArrayOutputStream dataStream = new ByteArrayOutputStream();
       byte[] buffer = new byte[1024];
       int bytesRead;
@@ -741,7 +752,7 @@
     try (Socket ignored = new Socket("localhost", port)) {
       return true;
     } catch (IOException e) {
-      LOG.debug("Port test result: {}", e.getMessage());
+      LOG.error("Port: {}, port check result: {}", port, e.getMessage());
       return false;
     }
   }
@@ -915,22 +926,55 @@
     conf.setInt(ShuffleHandler.SHUFFLE_PORT_CONFIG_KEY, TEST_EXECUTION.shuffleHandlerPort());
     conf.setBoolean(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_ENABLED, true);
     conf.setInt(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_TIME_OUT, TEST_EXECUTION.getKeepAliveTimeout());
-    testKeepAliveInternal(conf, ShuffleUrlType.SIMPLE, ShuffleUrlType.WITH_KEEPALIVE);
+    ShuffleHandlerForKeepAliveTests shuffleHandler = new ShuffleHandlerForKeepAliveTests(HEADER_WRITE_COUNT, ATTEMPT_ID);
+    testKeepAliveInternal(conf, shuffleHandler, ShuffleUrlType.SIMPLE, ShuffleUrlType.WITH_KEEPALIVE);
+  }
+
+  @Test(timeout = 1000000)
+  public void testKeepAliveInitiallyEnabled2() throws Exception {
+    Configuration conf = new Configuration();
+    conf.setInt(ShuffleHandler.SHUFFLE_PORT_CONFIG_KEY, TEST_EXECUTION.shuffleHandlerPort());
+    conf.setBoolean(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_ENABLED, true);
+    conf.setInt(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_TIME_OUT, TEST_EXECUTION.getKeepAliveTimeout());
+    ShuffleHandlerForKeepAliveTests shuffleHandler = new ShuffleHandlerForKeepAliveTests(HEADER_WRITE_COUNT, ATTEMPT_ID);
+    testKeepAliveInternal(conf, shuffleHandler, ShuffleUrlType.WITH_KEEPALIVE, ShuffleUrlType.WITH_KEEPALIVE);
   }
 
   //TODO snemeth implement keepalive test that used properly mocked ShuffleHandler
-  @Test(timeout = 10000)
+  @Test(timeout = 1000000)
   public void testKeepAliveInitiallyDisabled() throws Exception {
     Configuration conf = new Configuration();
     conf.setInt(ShuffleHandler.SHUFFLE_PORT_CONFIG_KEY, TEST_EXECUTION.shuffleHandlerPort());
     conf.setBoolean(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_ENABLED, false);
     conf.setInt(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_TIME_OUT, TEST_EXECUTION.getKeepAliveTimeout());
-    testKeepAliveInternal(conf, ShuffleUrlType.WITH_KEEPALIVE, ShuffleUrlType.WITH_KEEPALIVE);
+    ShuffleHandlerForKeepAliveTests shuffleHandler = new ShuffleHandlerForKeepAliveTests(HEADER_WRITE_COUNT, ATTEMPT_ID);
+    testKeepAliveInternal(conf, shuffleHandler, ShuffleUrlType.WITH_KEEPALIVE, ShuffleUrlType.WITH_KEEPALIVE);
   }
-  private void testKeepAliveInternal(Configuration conf, ShuffleUrlType... shuffleUrlTypes) throws IOException {
+
+  @Test(timeout = 1000000)
+  public void testKeepAliveMultipleMapAttemptIds() throws Exception {
+    Configuration conf = new Configuration();
+    conf.setInt(ShuffleHandler.SHUFFLE_PORT_CONFIG_KEY, TEST_EXECUTION.shuffleHandlerPort());
+    conf.setBoolean(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_ENABLED, true);
+    conf.setInt(ShuffleHandler.SHUFFLE_CONNECTION_KEEP_ALIVE_TIME_OUT, TEST_EXECUTION.getKeepAliveTimeout());
+    ShuffleHandlerForKeepAliveTests shuffleHandler = new ShuffleHandlerForKeepAliveTests(HEADER_WRITE_COUNT, ATTEMPT_ID);
+    shuffleHandler.mapOutputSender.additionalMapOutputSenderOperations = new AdditionalMapOutputSenderOperations() {
+      @Override
+      public void perform(ChannelHandlerContext ctx, Channel ch) throws IOException {
+        File tmpFile = File.createTempFile("test", ".tmp");
+        Files.write(tmpFile.toPath(), "testcontent123456".getBytes(StandardCharsets.UTF_8));
+        final DefaultFileRegion partition = new DefaultFileRegion(tmpFile, 0, 11);
+        LOG.info("***Writing response partition: {}, channel: {}", partition, ch.id());
+        ch.writeAndFlush(partition);
+      }
+    };
+    testKeepAliveInternal(conf, shuffleHandler, ShuffleUrlType.WITH_KEEPALIVE_MULTIPLE_MAP_IDS, ShuffleUrlType.WITH_KEEPALIVE_MULTIPLE_MAP_IDS);
+  }
+  
+  private void testKeepAliveInternal(Configuration conf, ShuffleHandlerForKeepAliveTests shuffleHandler, ShuffleUrlType... shuffleUrlTypes) throws IOException {
     Assert.assertTrue("Expected at least two shuffle URL types ",
         shuffleUrlTypes.length >= 2);
-    ShuffleHandlerForKeepAliveTests shuffleHandler = new ShuffleHandlerForKeepAliveTests(HEADER_WRITE_COUNT, ATTEMPT_ID);
+    
     shuffleHandler.init(conf);
     shuffleHandler.start();
 
@@ -940,6 +984,8 @@
         urls[i] = getShuffleUrl(shuffleHandler, ATTEMPT_ID, ATTEMPT_ID);
       } else if (shuffleUrlTypes[i] == ShuffleUrlType.WITH_KEEPALIVE) {
         urls[i] = getShuffleUrlWithKeepAlive(shuffleHandler, ATTEMPT_ID, ATTEMPT_ID);
+      } else if (shuffleUrlTypes[i] == ShuffleUrlType.WITH_KEEPALIVE_MULTIPLE_MAP_IDS) {
+        urls[i] = getShuffleUrlWithKeepAlive(shuffleHandler, ATTEMPT_ID, ATTEMPT_ID, ATTEMPT_ID); //TODO Use ATTEMPT_ID2
       }
     }
 
@@ -1703,18 +1749,29 @@
     testHandlingIdleState(timeoutSeconds, expectedTimeoutSeconds);
   }
 
-  private String getShuffleUrlWithKeepAlive(ShuffleHandler shuffleHandler, long jobId, long attemptId) {
-    String url = getShuffleUrl(shuffleHandler, jobId, attemptId);
+  private String getShuffleUrlWithKeepAlive(ShuffleHandler shuffleHandler, long jobId, long... attemptIds) {
+    String url = getShuffleUrl(shuffleHandler, jobId, attemptIds);
     return url + "&keepAlive=true";
   }
 
-  private String getShuffleUrl(ShuffleHandler shuffleHandler, long jobId, long attemptId) {
+  private String getShuffleUrl(ShuffleHandler shuffleHandler, long jobId, long... attemptIds) {
     String port = shuffleHandler.getConfig().get(ShuffleHandler.SHUFFLE_PORT_CONFIG_KEY);
     String shuffleBaseURL = "http://127.0.0.1:" + port;
+
+    StringBuilder mapAttemptIds = new StringBuilder();
+    for (int i = 0; i < attemptIds.length; i++) {
+      if (i == 0) {
+        mapAttemptIds.append("&map=");
+      } else {
+        mapAttemptIds.append(",");
+      }
+      mapAttemptIds.append(String.format("attempt_%s_1_m_1_0", attemptIds[i]));
+    }
+    
     String location = String.format("/mapOutput" +
         "?job=job_%s_1" +
         "&reduce=1" +
-        "&map=attempt_%s_1_m_1_0", jobId, attemptId);
+        "%s", jobId, mapAttemptIds.toString());
     return shuffleBaseURL + location;
   }
 
Index: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java
--- a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java	(revision 756a46c5ba22524a64bdd09a4adf6a6065c5d8c5)
+++ b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java	(date 1624397391336)
@@ -55,6 +55,7 @@
 import javax.crypto.SecretKey;
 
 import io.netty.bootstrap.ServerBootstrap;
+import io.netty.buffer.ByteBuf;
 import io.netty.buffer.Unpooled;
 import io.netty.channel.Channel;
 import io.netty.channel.ChannelFuture;
@@ -201,6 +202,7 @@
 
   //TODO snemeth add a config option for this later, this is temporarily disabled for now.
   private boolean useOutboundExceptionHandler = false;
+  private boolean useOutboundLogger = false;
   
   /**
    * Should the shuffle use posix_fadvise calls to manage the OS cache during
@@ -334,6 +336,7 @@
           future.channel().close();
         }
       } else {
+        LOG.info("***OPERATION COMPLETE");
         pipelineFact.getSHUFFLE().sendMap(reduceContext);
       }
     }
@@ -867,7 +870,14 @@
       pipeline.addLast("encoder", new HttpResponseEncoder());
       pipeline.addLast("chunking", new ChunkedWriteHandler());
       pipeline.addLast("shuffle", SHUFFLE);
-      
+      addOutboundHandlersIfRequired(pipeline);
+      pipeline.addLast(TIMEOUT_HANDLER, new TimeoutHandler(connectionKeepAliveTimeOut));
+      // TODO factor security manager into pipeline
+      // TODO factor out encode/decode to permit binary shuffle
+      // TODO factor out decode of index to permit alt. models
+    }
+
+    private void addOutboundHandlersIfRequired(ChannelPipeline pipeline) {
       if (useOutboundExceptionHandler) {
         //https://stackoverflow.com/questions/50612403/catch-all-exception-handling-for-outbound-channelhandler
         pipeline.addLast("outboundExcHandler", new ChannelOutboundHandlerAdapter() {
@@ -878,10 +888,9 @@
           }
         });
       }
-      pipeline.addLast(TIMEOUT_HANDLER, new TimeoutHandler(connectionKeepAliveTimeOut));
-      // TODO factor security manager into pipeline
-      // TODO factor out encode/decode to permit binary shuffle
-      // TODO factor out decode of index to permit alt. models
+      if (useOutboundLogger) {
+        pipeline.addLast("loggingResponseEncoder", new LoggingHttpResponseEncoder(false));
+      }
     }
   }
 
@@ -977,8 +986,9 @@
     @Override
     public void channelRead(ChannelHandlerContext ctx, Object msg)
         throws Exception {
-      LOG.debug("channelRead");
+      LOG.info("***channelRead");
       HttpRequest request = (HttpRequest) msg;
+      LOG.info("***REQUEST: " + request);
       if (request.method() != GET) {
           sendError(ctx, METHOD_NOT_ALLOWED);
           return;
@@ -1077,38 +1087,71 @@
         // is quite a non-standard way of crafting HTTP responses,
         // but we need to keep backward compatibility.
         // See more details in jira.
-        ch.writeAndFlush(response);
-        ch.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT);
-        LOG.error("Shuffle error in populating headers :", e);
+        writeToChannelAndAddLastHttpContent(ch, response);
+        LOG.error("Shuffle error while populating headers :", e);
         String errorMessage = getErrorMessage(e);
         sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);
         return;
       }
-      LOG.debug("Writing response: " + response);
-      ch.writeAndFlush(response).addListener(new ChannelFutureListener() {
-        @Override
-        public void operationComplete(ChannelFuture future) {
-          if (future.isSuccess()) {
-            LOG.debug("Written HTTP response object successfully");
-          } else {
-            LOG.error("Error while writing HTTP response object: {}", response);
-          }
+      writeToChannel(ch, response).addListener((ChannelFutureListener) future -> {
+        if (future.isSuccess()) {
+          LOG.debug("Written HTTP response object successfully");
+        } else {
+          LOG.error("Error while writing HTTP response object: {}", response);
         }
       });
       //Initialize one ReduceContext object per channelRead call
       boolean keepAlive = keepAliveParam || connectionKeepAliveEnabled;
       ReduceContext reduceContext = new ReduceContext(mapIds, reduceId, ctx,
           user, mapOutputInfoMap, jobId, keepAlive);
-      LOG.debug("After response");
       for (int i = 0; i < Math.min(maxSessionOpenFiles, mapIds.size()); i++) {
+        LOG.info("***LOOP" + (i + 1));
         ChannelFuture nextMap = sendMap(reduceContext);
         if(nextMap == null) {
           return;
         }
       }
+      LOG.info("***LOOP ENDED");
       //HADOOP-15327: Need to send an instance of LastHttpContent to define HTTP
       //message boundaries. See details in jira.
-      ch.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT);
+      writeLastHttpContentToChannel(ch);
+    }
+
+    private ChannelFuture writeToChannelAndAddLastHttpContent(Channel ch, HttpResponse response) {
+      LOG.info("***Writing Response, channel: {}", ch.id());
+      ch.writeAndFlush(response);
+      LOG.info("***Writing LastHttpContent, channel: {}", ch.id());
+      return ch.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT);
+    }
+
+    private ChannelFuture writeToChannel(Channel ch, FadvisedFileRegion partition) {
+      LOG.info("***Writing FadvisedFileRegion, channel: {}", ch.id());
+      return ch.writeAndFlush(partition);
+    }
+
+    private ChannelFuture writeToChannel(Channel ch, FadvisedChunkedFile chunkedFile) {
+      LOG.info("***Writing FadvisedChunkedFile, channel: {}", ch.id());
+      return ch.writeAndFlush(chunkedFile);
+    }
+
+    private ChannelFuture writeToChannel(Channel ch, HttpResponse response) {
+      LOG.info("***Writing Response, channel: {}", ch.id());
+      return ch.writeAndFlush(response);
+    }
+
+    private ChannelFuture writeToChannel(Channel ch, ByteBuf byteBuf, int bufferLength) {
+      LOG.info("***Writing response buffer: {}, channel: {}", bufferLength, ch.id());
+      return ch.writeAndFlush(byteBuf);
+    }
+
+    private ChannelFuture writeLastHttpContentToChannel(Channel ch) {
+      LOG.info("***Writing LastHttpContent, channel: {}", ch.id());
+      return ch.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT);
+    }
+
+    private void writeToChannelAndClose(Channel ch, FullHttpResponse response) {
+      LOG.info("***Writing response and closing, channel: {}", ch.id());
+      ch.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE);
     }
 
     /**
@@ -1336,7 +1379,8 @@
         new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);
       final DataOutputBuffer dob = new DataOutputBuffer();
       header.write(dob);
-      ch.writeAndFlush(wrappedBuffer(dob.getData(), 0, dob.getLength()));
+      ByteBuf byteBuf = wrappedBuffer(dob.getData(), 0, dob.getLength());
+      writeToChannel(ch, byteBuf, dob.getLength());
       final File spillfile =
           new File(mapOutputInfo.mapOutputFileName.toString());
       RandomAccessFile spill;
@@ -1352,10 +1396,11 @@
             info.startOffset, info.partLength, manageOsCache, readaheadLength,
             readaheadPool, spillfile.getAbsolutePath(), 
             shuffleBufferSize, shuffleTransferToAllowed);
-        writeFuture = ch.writeAndFlush(partition);
+        LOG.info("***Writing response partition: {}, channel: {}", partition, ch.id());
+        writeFuture = writeToChannel(ch, partition);
         writeFuture.addListener(new ChannelFutureListener() {
-            // TODO error handling; distinguish IO/connection failures,
-            //      attribute to appropriate spill output
+          // TODO error handling; distinguish IO/connection failures,
+          //      attribute to appropriate spill output
           @Override
           public void operationComplete(ChannelFuture future) {
             if (future.isSuccess()) {
@@ -1370,7 +1415,7 @@
             info.startOffset, info.partLength, sslFileBufferSize,
             manageOsCache, readaheadLength, readaheadPool,
             spillfile.getAbsolutePath());
-        writeFuture = ch.writeAndFlush(chunk);
+        writeFuture = writeToChannel(ch, chunk);
       }
       metrics.shuffleConnections.incr();
       metrics.shuffleOutputBytes.incr(info.partLength); // optimistic
@@ -1402,7 +1447,7 @@
       }
 
       // Close the connection as soon as the error message is sent.
-      ctx.channel().writeAndFlush(response).addListener(ChannelFutureListener.CLOSE);
+      writeToChannelAndClose(ctx.channel(), response);
     }
 
     @Override
@@ -1430,7 +1475,7 @@
       }
     }
   }
-  
+
   static class AttemptPathInfo {
     // TODO Change this over to just store local dir indices, instead of the
     // entire path. Far more efficient.
